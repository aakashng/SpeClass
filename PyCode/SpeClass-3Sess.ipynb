{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import graphlab\n",
    "import scipy #to save mat files\n",
    "import time  #to time code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#balanced accuracy\n",
    "def Balanced_acc(ypred,ytest):\n",
    "    acc_c = 0\n",
    "    acc_class = np.zeros(5) #the accuracy per class\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "        acc_class[c] = sum(correct)/len(correct)\n",
    "\n",
    "    Bacc = acc_c/len(np.unique(ytest))\n",
    "    return Bacc,acc_class\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(5)\n",
    "    plt.xticks(tick_marks, ['Sit','StairsDw','StairsUp','Stand','Walk'], rotation=45)\n",
    "    plt.yticks(tick_marks, ['Sit','StairsDw','StairsUp','Stand','Walk'])\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def prec_rec(cmat):\n",
    "    tpfp = cmat.sum(axis=1)\n",
    "    tpfn = cmat.sum(axis=0)\n",
    "    prec = cmat.diagonal()/tpfp\n",
    "    recall = cmat.diagonal()/tpfn\n",
    "    return prec,recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HealthyData = graphlab.SFrame.read_csv('../../Datasets/Cbrace/HealthyData.csv',verbose=False)\n",
    "CBRData = graphlab.SFrame.read_csv('../../Datasets/Cbrace/PatientCBRData.csv',verbose=False)\n",
    "SCOData = graphlab.SFrame.read_csv('../../Datasets/Cbrace/PatientSCOData.csv',verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51 52 53 54 55 56 57 58 59 60 61]\n",
      "[1L, 2L, 5L, 6L, 8L, 11L, 12L, 13L, 14L, 15L, 16L, 19L, 21L, 24L]\n"
     ]
    }
   ],
   "source": [
    "HealthyCodes = HealthyData['SubjID'].unique()\n",
    "HealthyCodes = HealthyCodes.sort()\n",
    "HealthyCodes = HealthyCodes.to_numpy()\n",
    "print HealthyCodes\n",
    "PatientCodes = CBRData['SubjID'].unique()\n",
    "PatientCodes = PatientCodes.sort()\n",
    "print PatientCodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PatientCodes = np.array([1, 2, 5, 6, 8, 11, 14, 15, 16, 19, 24]) #patients with enough sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use 3 sessions for CBR and SCO data. Remove stairs in CBR data for patients who don't have at least 2 sessions with stairs data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect SCO Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 [0 1 2 3 4]\n",
      "1 2 [0 1 2 3 4]\n",
      "1 3 [0 1 2 3 4]\n",
      "1 4 [0 1 2 3 4]\n",
      "1 5 [0 1 2 3 4]\n",
      "2 1 [0 1 2 3 4]\n",
      "2 2 [0 1 2 3 4]\n",
      "2 3 [0 3 4]\n",
      "2 4 [0 1 2 3 4]\n",
      "2 5 [0 3 4]\n",
      "2 6 [3 4]\n",
      "2 7 [0 2 3 4]\n",
      "2 8 [0 1 3 4]\n",
      "2 9 [0 3 4]\n",
      "5 1 [0 3 4]\n",
      "5 2 [0 1 2 3 4]\n",
      "5 3 [0 1 2 3 4]\n",
      "6 1 [0 1 2 3 4]\n",
      "6 2 [0 1 2 3 4]\n",
      "6 3 [0 1 2 3 4]\n",
      "6 4 [0 1 2 3 4]\n",
      "6 5 [0 1 2 3 4]\n",
      "6 6 [1 2 3 4]\n",
      "8 1 [0 1 2 3 4]\n",
      "8 2 [0 3 4]\n",
      "8 3 [0 3 4]\n",
      "8 4 [0 3 4]\n",
      "8 5 [0 3 4]\n",
      "11 1 [0 3 4]\n",
      "11 2 [0 3 4]\n",
      "11 3 [0 3 4]\n",
      "11 4 [0 1 2 3 4]\n",
      "11 5 [0 1 2 3 4]\n",
      "11 6 [0 1 2 3 4]\n",
      "14 1 [0 1 2 3 4]\n",
      "14 2 [0 1 2 3 4]\n",
      "14 3 [0 1 2 3 4]\n",
      "14 4 [0 1 2 3 4]\n",
      "15 1 [0 3 4]\n",
      "15 2 [0 3 4]\n",
      "15 3 [0 1 2 3 4]\n",
      "16 1 [0 1 2 3 4]\n",
      "16 2 [0 3 4]\n",
      "16 3 [0 1 2 3 4]\n",
      "16 4 [0 1 2 3 4]\n",
      "16 5 [0 1 2 3 4]\n",
      "16 6 [0 3 4]\n",
      "19 1 [0 3 4]\n",
      "19 2 [0 1 2 3 4]\n",
      "19 3 [0 3 4]\n",
      "24 1 [0 1 2 3 4]\n",
      "24 2 [0 1 2 3 4]\n",
      "24 3 [0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "for s in PatientCodes:\n",
    "    data = SCOData[SCOData['SubjID']==s]\n",
    "    for sess in np.unique(data['Session']):\n",
    "        print s,sess,np.unique(data[data['Session']==sess]['Label'].unique().sort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28276\n"
     ]
    }
   ],
   "source": [
    "print SCOData.num_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the 3 sessions to keep for patients who have a variable number of activities in each session\n",
    "* CBR01: 1,2,3\n",
    "* CBR05: 1,2,3\n",
    "* CBR06: 1,2,3\n",
    "* CBR08: 1,2,3\n",
    "* CBR14: 1,2,3\n",
    "* CBR15: 1,2,3\n",
    "* CBR19: 1,2,3\n",
    "* CBR24: 1,2,3\n",
    "\n",
    "\n",
    "* CBR02: 1,2,4\n",
    "* CBR11: 4,5,6\n",
    "* CBR16: 1,3,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tochange =[1,5,6,8,14,15,19,24]\n",
    "SCODatanew = SCOData.filter_by(tochange,'SubjID')\n",
    "SCODatanew = SCODatanew.filter_by([1,2,3],'Session')\n",
    "\n",
    "data = SCOData[SCOData['SubjID']==2].filter_by([1,2,4],'Session')\n",
    "SCODatanew = SCODatanew.append(data)\n",
    "data = SCOData[SCOData['SubjID']==11].filter_by([4,5,6],'Session')\n",
    "SCODatanew = SCODatanew.append(data)\n",
    "data = SCOData[SCOData['SubjID']==16].filter_by([1,3,4],'Session')\n",
    "SCODatanew = SCODatanew.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17614\n"
     ]
    }
   ],
   "source": [
    "print SCODatanew.num_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCOData = SCODatanew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect CBR Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29175\n"
     ]
    }
   ],
   "source": [
    "print CBRData.num_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 [0 1 2 3 4]\n",
      "1 2 [0 1 2 3 4]\n",
      "1 3 [0 1 2 3 4]\n",
      "1 4 [0 1 2 3 4]\n",
      "1 5 [0 1 2 3 4]\n",
      "1 6 [0 1 2 3 4]\n",
      "2 1 [0 1 2 3 4]\n",
      "2 2 [0 1 2 3 4]\n",
      "2 3 [0 1 2 3 4]\n",
      "2 4 [0 1 2 3 4]\n",
      "5 1 [0 1 2 3 4]\n",
      "5 2 [0 1 2 3 4]\n",
      "5 3 [0 1 2 3 4]\n",
      "5 4 [0 1 2 3 4]\n",
      "5 5 [0 1 2 3 4]\n",
      "6 1 [0 1 3 4]\n",
      "6 2 [0 1 2 3 4]\n",
      "6 3 [0 1 2 3 4]\n",
      "6 4 [0 1 2 3 4]\n",
      "8 1 [0 3 4]\n",
      "8 2 [0 3 4]\n",
      "8 3 [0 3 4]\n",
      "8 4 [0 1 2 3 4]\n",
      "8 5 [0 3 4]\n",
      "11 1 [0 3 4]\n",
      "11 2 [0 1 2 3 4]\n",
      "11 3 [0 1 2 3 4]\n",
      "11 4 [0 1 2 3 4]\n",
      "14 1 [0 3 4]\n",
      "14 2 [0 3 4]\n",
      "14 3 [0 1 2 3 4]\n",
      "14 4 [0 1 2 3 4]\n",
      "14 5 [0 1 2 3 4]\n",
      "15 1 [0 3 4]\n",
      "15 2 [0 1 2 3 4]\n",
      "15 3 [0 3 4]\n",
      "15 4 [0 1 2 3 4]\n",
      "16 1 [0 1 2 3 4]\n",
      "16 2 [0 1 2 3 4]\n",
      "16 3 [0 1 2 3 4]\n",
      "16 4 [0 1 2 3 4]\n",
      "19 1 [0 3 4]\n",
      "19 2 [0 3 4]\n",
      "19 3 [0 3 4]\n",
      "19 4 [0 3 4]\n",
      "24 1 [0 1 2 3 4]\n",
      "24 2 [0 1 2 3 4]\n",
      "24 3 [0 1 2 3 4]\n",
      "24 4 [0 1 2 3 4]\n",
      "24 5 [0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "for s in PatientCodes:\n",
    "    data = CBRData[CBRData['SubjID']==s]\n",
    "    for sess in np.unique(data['Session']):\n",
    "        print s,sess,np.unique(data[data['Session']==sess]['Label'].unique().sort())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Sessions to keep\n",
    "* CBR01 1,2,3\n",
    "* CBR02 1,2,3\n",
    "* CBR05 1,2,3\n",
    "* CBR08 1,2,3\n",
    "* CBR16 1,2,3\n",
    "* CBR19 1,2,3\n",
    "* CBR24 1,2,3 (Session 1 might have problems!)\n",
    "\n",
    "\n",
    "* CBR06 2,3,4\n",
    "* CBR11 2,3,4\n",
    "* CBR14 3,4,5\n",
    "* CBR15 2,3,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rename sessions to 1,2,3\n",
    "def updatesess(x,c):\n",
    "    x = x-c\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tochange =[1,2,5,8,16,19,24]\n",
    "CBRDatanew = CBRData.filter_by(tochange,'SubjID')\n",
    "CBRDatanew = CBRDatanew.filter_by([1,2,3],'Session')\n",
    "\n",
    "data = CBRData[((CBRData['SubjID']==6) | (CBRData['SubjID']==11))].filter_by([2,3,4],'Session')\n",
    "data['Session'] = data['Session'].apply(lambda x: x-1) #rename sessions to 1,2,3\n",
    "CBRDatanew = CBRDatanew.append(data)\n",
    "\n",
    "data = CBRData[CBRData['SubjID']==14].filter_by([3,4,5],'Session')\n",
    "data['Session'] = data['Session'].apply(lambda x: x-2) #rename sessions to 1,2,3\n",
    "CBRDatanew = CBRDatanew.append(data)\n",
    "\n",
    "data = CBRData[CBRData['SubjID']==15].filter_by([2,3,4],'Session')\n",
    "data['Session'] = data['Session'].apply(lambda x: x-1) #rename sessions to 1,2,3\n",
    "CBRDatanew = CBRDatanew.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16496\n"
     ]
    }
   ],
   "source": [
    "print CBRDatanew.num_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CBRData = CBRDatanew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Healthy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on Patient 1, Train samples=8375, Test samples=1288, Nclass test=5\n",
      "BAcc = 0.49\n",
      "Test on Patient 2, Train samples=8375, Test samples=991, Nclass test=5\n",
      "BAcc = 0.35\n",
      "Test on Patient 5, Train samples=8375, Test samples=1358, Nclass test=5\n",
      "BAcc = 0.44\n",
      "Test on Patient 6, Train samples=8375, Test samples=2246, Nclass test=5\n",
      "BAcc = 0.59\n",
      "Test on Patient 8, Train samples=8375, Test samples=856, Nclass test=3\n",
      "BAcc = 0.32\n",
      "Test on Patient 11, Train samples=8375, Test samples=1207, Nclass test=5\n",
      "BAcc = 0.55\n",
      "Test on Patient 14, Train samples=8375, Test samples=1778, Nclass test=5\n",
      "BAcc = 0.56\n",
      "Test on Patient 15, Train samples=8375, Test samples=3177, Nclass test=5\n",
      "BAcc = 0.48\n",
      "Test on Patient 16, Train samples=8375, Test samples=1126, Nclass test=5\n",
      "BAcc = 0.54\n",
      "Test on Patient 19, Train samples=8375, Test samples=1020, Nclass test=3\n",
      "BAcc = 0.53\n",
      "Test on Patient 24, Train samples=8375, Test samples=1449, Nclass test=5\n",
      "BAcc = 0.64\n",
      "\n",
      "median Bacc - Healthy model = 0.527559074912\n"
     ]
    }
   ],
   "source": [
    "col_names = HealthyData.column_names()\n",
    "label_cols = col_names[-1:] #the : is used to return a list with one element \n",
    "feature_cols = col_names[2:-1]\n",
    "\n",
    "Xtrain = HealthyData.select_columns(feature_cols).to_numpy()\n",
    "ytrain = HealthyData.select_columns(label_cols).to_numpy()\n",
    "ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=50)\n",
    "RF = RF.fit(Xtrain,ytrain)\n",
    "\n",
    "#test on each patient (CBR)\n",
    "SOacc = np.zeros(len(PatientCodes))\n",
    "acc_class_subj = [] #accuracy per class for each subject\n",
    "cmat_H = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_H = {} \n",
    "recall_H ={}\n",
    "k = 0\n",
    "\n",
    "for s in PatientCodes:\n",
    "    test = CBRData[(CBRData['SubjID'] == s)]\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "    print 'Test on Patient %s, Train samples=%s, Test samples=%s, Nclass test=%s'%(s,len(ytrain),len(ytest),Nclasses)\n",
    "    ypred = RF.predict(Xtest)\n",
    "\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #SOacc[k] = acc\n",
    "\n",
    "    #balanced accuracy\n",
    "    SOacc[k],acc_class = Balanced_acc(ypred,ytest)\n",
    "    acc_class_subj.append(acc_class)  \n",
    "    \n",
    "    #confusion matrix\n",
    "    cmat = confusion_matrix(ytest, ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "    prec,recall = prec_rec(cmat)\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(s) #subj code\n",
    "    cmat_H.update({key:cmat})\n",
    "    prec_H.update({s:prec})\n",
    "    recall_H.update({s:recall})\n",
    "    \n",
    "    print 'BAcc = {:.2f}'.format(SOacc[k])\n",
    "    k = k+1\n",
    "\n",
    "print '\\nmedian Bacc - Healthy model = %s'%np.median(SOacc)\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_H_mean = np.nanmean(np.asarray(prec_H.values()),axis=0)\n",
    "rec_H_mean = np.nanmean(np.asarray(recall_H.values()),axis=0)\n",
    "#acc_class_subj_mean = np.nanmean(acc_class_subj,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save data\n",
    "#save the dict to matlab format \n",
    "scipy.io.savemat('cmatHealthy',cmat_H)\n",
    "np.savetxt('precisionHealthy.csv', prec_H_mean, delimiter=',') \n",
    "np.savetxt('recallHealthy.csv', rec_H_mean, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global model SCO (Leave one subject out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Nclass train = 5, Nclass test = 5, Nsamples train = 16679.0, Global SCO - BAcc = 0.54\n",
      "Patient 2, Nclass train = 5, Nclass test = 5, Nsamples train = 16200.0, Global SCO - BAcc = 0.51\n",
      "Patient 5, Nclass train = 5, Nclass test = 5, Nsamples train = 15238.0, Global SCO - BAcc = 0.51\n",
      "Patient 6, Nclass train = 5, Nclass test = 5, Nsamples train = 16538.0, Global SCO - BAcc = 0.55\n",
      "Patient 8, Nclass train = 5, Nclass test = 3, Nsamples train = 15432.0, Global SCO - BAcc = 0.46\n",
      "Patient 11, Nclass train = 5, Nclass test = 5, Nsamples train = 15978.0, Global SCO - BAcc = 0.52\n",
      "Patient 14, Nclass train = 5, Nclass test = 5, Nsamples train = 16008.0, Global SCO - BAcc = 0.58\n",
      "Patient 15, Nclass train = 5, Nclass test = 5, Nsamples train = 15751.0, Global SCO - BAcc = 0.57\n",
      "Patient 16, Nclass train = 5, Nclass test = 5, Nsamples train = 15430.0, Global SCO - BAcc = 0.52\n",
      "Patient 19, Nclass train = 5, Nclass test = 3, Nsamples train = 16359.0, Global SCO - BAcc = 0.86\n",
      "Patient 24, Nclass train = 5, Nclass test = 5, Nsamples train = 16527.0, Global SCO - BAcc = 0.59\n",
      "Median BAcc - Impairment Specific (SCO) = 0.536925391883\n",
      "Avg train size = 16012.7272727\n"
     ]
    }
   ],
   "source": [
    "ISpec_acc = np.zeros(len(PatientCodes)) \n",
    "Nsamples = np.zeros(len(PatientCodes))\n",
    "acc_class_subj = [] #accuracy per class for each subject\n",
    "\n",
    "cmat_ISpec = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_ISpec = {} \n",
    "recall_ISpec ={}\n",
    "\n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = SCOData[(SCOData['SubjID'] != s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s)] \n",
    "    Nclasstrain = len(train['Label'].unique())\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    Nsamples[k] = ytrain.shape[0]\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=100)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    ISpec_acc[k],acc_class = Balanced_acc(ypred,ytest)\n",
    "    acc_class_subj.append(acc_class)\n",
    "    \n",
    "    #confusion matrix\n",
    "    cmat = confusion_matrix(ytest, ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "    prec,recall = prec_rec(cmat)\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(s) #subj code\n",
    "    cmat_ISpec.update({key:cmat})\n",
    "    prec_ISpec.update({s:prec})\n",
    "    recall_ISpec.update({s:recall})\n",
    "\n",
    "    print 'Patient {}, Nclass train = {}, Nclass test = {}, Nsamples train = {}, Global SCO - BAcc = {:.2f}'.format(s,Nclasstrain,Nclasses,Nsamples[k],ISpec_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Median BAcc - Impairment Specific (SCO) = %s'%np.median(ISpec_acc)\n",
    "print 'Avg train size = {}'.format(np.mean(Nsamples))\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_ISpec_mean = np.nanmean(np.asarray(prec_ISpec.values()),axis=0)\n",
    "rec_ISpec_mean = np.nanmean(np.asarray(recall_ISpec.values()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save the dict to matlab format \n",
    "scipy.io.savemat('cmatISpec',cmat_ISpec)\n",
    "np.savetxt('precisionISpec.csv', prec_ISpec_mean, delimiter=',') \n",
    "np.savetxt('recallISpec.csv', rec_ISpec_mean, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global model CBR (Leave one subject out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Nclass train = 5, Nclass test = 5, Global CBR model - BAcc = 0.63\n",
      "Patient 2, Nclass train = 5, Nclass test = 5, Global CBR model - BAcc = 0.48\n",
      "Patient 5, Nclass train = 5, Nclass test = 5, Global CBR model - BAcc = 0.52\n",
      "Patient 6, Nclass train = 5, Nclass test = 5, Global CBR model - BAcc = 0.59\n",
      "Patient 8, Nclass train = 5, Nclass test = 3, Global CBR model - BAcc = 0.62\n",
      "Patient 11, Nclass train = 5, Nclass test = 5, Global CBR model - BAcc = 0.57\n",
      "Patient 14, Nclass train = 5, Nclass test = 5, Global CBR model - BAcc = 0.60\n",
      "Patient 15, Nclass train = 5, Nclass test = 5, Global CBR model - BAcc = 0.67\n",
      "Patient 16, Nclass train = 5, Nclass test = 5, Global CBR model - BAcc = 0.59\n",
      "Patient 19, Nclass train = 5, Nclass test = 3, Global CBR model - BAcc = 0.90\n",
      "Patient 24, Nclass train = 5, Nclass test = 5, Global CBR model - BAcc = 0.66\n",
      "Median BAcc - Global CBR model = 0.602154346755\n"
     ]
    }
   ],
   "source": [
    "ISpecCBR_acc = np.zeros(len(PatientCodes)) \n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = CBRData[(CBRData['SubjID'] != s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s)] #test on 3 CBR sessions\n",
    "    Nclasstrain = len(train['Label'].unique())\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    ISpecCBR_acc[k],acc_class = Balanced_acc(ypred,ytest)\n",
    "    acc_class_subj.append(acc_class)   \n",
    "    print 'Patient {}, Nclass train = {}, Nclass test = {}, Global CBR model - BAcc = {:.2f}'.format(s,Nclasstrain,Nclasses,ISpecCBR_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Median BAcc - Global CBR model = %s'%np.median(ISpecCBR_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal SCO (Patient Specific model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Nclass train = 5, Nclass test = 5,  Nsamples train = 935.0, Personal SCO - BAcc = 0.68\n",
      "Patient 2, Nclass train = 5, Nclass test = 5,  Nsamples train = 1414.0, Personal SCO - BAcc = 0.55\n",
      "Patient 5, Nclass train = 5, Nclass test = 5,  Nsamples train = 2376.0, Personal SCO - BAcc = 0.67\n",
      "Patient 6, Nclass train = 5, Nclass test = 5,  Nsamples train = 1076.0, Personal SCO - BAcc = 0.65\n",
      "Patient 8, Nclass train = 5, Nclass test = 3,  Nsamples train = 2182.0, Personal SCO - BAcc = 0.74\n",
      "Patient 11, Nclass train = 5, Nclass test = 5,  Nsamples train = 1636.0, Personal SCO - BAcc = 0.47\n",
      "Patient 14, Nclass train = 5, Nclass test = 5,  Nsamples train = 1606.0, Personal SCO - BAcc = 0.48\n",
      "Patient 15, Nclass train = 5, Nclass test = 5,  Nsamples train = 1863.0, Personal SCO - BAcc = 0.41\n",
      "Patient 16, Nclass train = 5, Nclass test = 5,  Nsamples train = 2184.0, Personal SCO - BAcc = 0.51\n",
      "Patient 19, Nclass train = 5, Nclass test = 3,  Nsamples train = 1255.0, Personal SCO - BAcc = 0.72\n",
      "Patient 24, Nclass train = 5, Nclass test = 5,  Nsamples train = 1087.0, Personal SCO - BAcc = 0.74\n",
      "Median BAcc - Patient Specific (SCO) = 0.653458098257\n",
      "Avg train size = 1601.27272727\n"
     ]
    }
   ],
   "source": [
    "PSpec_acc = np.zeros(len(PatientCodes)) \n",
    "Nsamples = np.zeros(len(PatientCodes))\n",
    "acc_class_subj = [] #accuracy per class for each subject\n",
    "\n",
    "cmat_PSpec = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_PSpec = {} \n",
    "recall_PSpec ={}\n",
    "\n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = SCOData[(SCOData['SubjID'] == s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s)]\n",
    "    Nclasstrain = len(train['Label'].unique())\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    Nsamples[k] = ytrain.shape[0]\n",
    "\n",
    "    RF = RandomForestClassifier(n_estimators=50)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    PSpec_acc[k],acc_class = Balanced_acc(ypred,ytest)\n",
    "    \n",
    "    #confusion matrix\n",
    "    cmat = confusion_matrix(ytest, ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "    prec,recall = prec_rec(cmat)\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(s) #subj code\n",
    "    cmat_PSpec.update({key:cmat})\n",
    "    prec_PSpec.update({s:prec})\n",
    "    recall_PSpec.update({s:recall})\n",
    "    \n",
    "    print 'Patient {}, Nclass train = {}, Nclass test = {},  Nsamples train = {}, Personal SCO - BAcc = {:.2f}'.format(s,Nclasstrain,Nclasses,Nsamples[k],PSpec_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Median BAcc - Patient Specific (SCO) = %s'%np.median(PSpec_acc)\n",
    "print 'Avg train size = {}'.format(np.mean(Nsamples))\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_PSpec_mean = np.nanmean(np.asarray(prec_PSpec.values()),axis=0)\n",
    "rec_PSpec_mean = np.nanmean(np.asarray(recall_PSpec.values()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the dict to matlab format \n",
    "scipy.io.savemat('cmatPSpec',cmat_PSpec)\n",
    "np.savetxt('precisionPSpec.csv', prec_PSpec_mean, delimiter=',') \n",
    "np.savetxt('recallPSpec.csv', rec_PSpec_mean, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal CBR (Patient and Device specific model) \n",
    "Leave One Session Out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nclass train = 5, Nclass test =5, BAcc = 0.73\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.86\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.78\n",
      "Patient 1, Device Specific model - BAcc = 0.79\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.74\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.53\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.76\n",
      "Patient 2, Device Specific model - BAcc = 0.68\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.72\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.56\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.60\n",
      "Patient 5, Device Specific model - BAcc = 0.63\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.58\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.74\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.85\n",
      "Patient 6, Device Specific model - BAcc = 0.73\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.93\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.74\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.89\n",
      "Patient 8, Device Specific model - BAcc = 0.85\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.41\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.57\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.51\n",
      "Patient 11, Device Specific model - BAcc = 0.50\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.70\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.67\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.88\n",
      "Patient 14, Device Specific model - BAcc = 0.75\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.68\n",
      "Nclass train = 5, Nclass test =3, BAcc = 0.97\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.60\n",
      "Patient 15, Device Specific model - BAcc = 0.75\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.59\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.62\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.75\n",
      "Patient 16, Device Specific model - BAcc = 0.66\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.55\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.98\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.85\n",
      "Patient 19, Device Specific model - BAcc = 0.80\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.87\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.84\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.61\n",
      "Patient 24, Device Specific model - BAcc = 0.77\n",
      "Median BAcc - Device Specific (CBR) = 0.750058328901\n",
      "Avg train size = 999.757575758\n"
     ]
    }
   ],
   "source": [
    "DSpec_acc = np.zeros(len(PatientCodes)) \n",
    "Nsamples = np.zeros(len(PatientCodes))\n",
    "Nsessions = 3\n",
    "\n",
    "cmat_DSpec = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_DSpec = {} \n",
    "recall_DSpec ={}\n",
    "k = 0\n",
    "\n",
    "for s in PatientCodes:\n",
    "    cmat = np.zeros((5,5)) #temporary arrays to store cmat, prec and recall in each session\n",
    "    prec = np.zeros(5)\n",
    "    recall = np.zeros(5)\n",
    "\n",
    "    data =  CBRData[(CBRData['SubjID'] == s)] \n",
    "    Bacc = np.zeros(Nsessions)\n",
    "    for session in range(1,Nsessions+1):\n",
    "                  \n",
    "        test = data[data['Session'] == session]\n",
    "        train = data[data['Session'] != session]\n",
    "        Nclasstrain = len(train['Label'].unique())\n",
    "        Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "        Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "        ytrain = train.select_columns(label_cols).to_numpy()\n",
    "        ytrain = ytrain.reshape(-1)\n",
    "        Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "        ytest = test.select_columns(label_cols).to_numpy()\n",
    "        ytest = ytest.reshape(-1)\n",
    "        Nsamples[k] = Nsamples[k]+ytrain.shape[0]\n",
    "\n",
    "        RF = RandomForestClassifier(n_estimators=50)\n",
    "        RF = RF.fit(Xtrain,ytrain)\n",
    "        ypred = RF.predict(Xtest)\n",
    "        #acc = sum(ypred == ytest)/len(ytest)\n",
    "        #balanced accuracy on each session\n",
    "        Bacc[session-1],acc_class = Balanced_acc(ypred,ytest)\n",
    "        print 'Nclass train = {}, Nclass test ={}, BAcc = {:.2f}'.format(Nclasstrain,Nclasses,Bacc[session-1])\n",
    "        \n",
    "        #confusion matrix, prec and recall in each session\n",
    "        cmat_tmp = confusion_matrix(ytest,ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "        cmat += cmat_tmp\n",
    "        pr,re = prec_rec(cmat_tmp)\n",
    "        prec += pr\n",
    "        recall += re\n",
    "\n",
    "    DSpec_acc[k] = Bacc.mean() #the CV BAcc on 3 sessions \n",
    "    Nsamples[k] = Nsamples[k]/len(range(1,Nsessions+1)) #mean number of samples across sessions    \n",
    "    #mean confusion matrix (instances), precision and recall on 3 sessions\n",
    "    avgcmat = cmat/Nsessions\n",
    "    prec = prec/Nsessions\n",
    "    recall = recall/Nsessions\n",
    "\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(s) #subj code\n",
    "    cmat_DSpec.update({key:avgcmat})     #the confusion matrix with instances from the 4 sessions\n",
    "    prec_DSpec.update({s:prec})\n",
    "    recall_DSpec.update({s:recall})\n",
    "   \n",
    "    print 'Patient {}, Device Specific model - BAcc = {:.2f}'.format(s,DSpec_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Median BAcc - Device Specific (CBR) = %s'%(np.median(DSpec_acc))\n",
    "print 'Avg train size = {}'.format(np.mean(Nsamples))\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_DSpec_mean = np.nanmean(np.asarray(prec_DSpec.values()),axis=0)\n",
    "rec_DSpec_mean = np.nanmean(np.asarray(recall_DSpec.values()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save the dict to matlab format \n",
    "scipy.io.savemat('cmatDSpec',cmat_DSpec)\n",
    "np.savetxt('precisionDSpec.csv', prec_DSpec_mean, delimiter=',') \n",
    "np.savetxt('recallDSpec.csv', rec_DSpec_mean, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble results for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.48535194  0.53692539  0.67664414  0.79241262]\n",
      " [ 0.3515961   0.51197473  0.54601922  0.67683603]\n",
      " [ 0.44056993  0.50913549  0.66776726  0.62602252]\n",
      " [ 0.59288692  0.54727797  0.6534581   0.72588645]\n",
      " [ 0.32384092  0.46127719  0.73957038  0.85315801]\n",
      " [ 0.54824434  0.52203818  0.47378895  0.49686033]\n",
      " [ 0.56026729  0.58453206  0.48197107  0.75041308]\n",
      " [ 0.48445162  0.57389076  0.41010355  0.75005833]\n",
      " [ 0.53628769  0.51675169  0.5079865   0.65581682]\n",
      " [ 0.52755907  0.86254285  0.71983043  0.79622739]\n",
      " [ 0.6397085   0.58875641  0.74381602  0.7744993 ]]\n"
     ]
    }
   ],
   "source": [
    "acc_all=np.vstack((SOacc,ISpec_acc,PSpec_acc,DSpec_acc)).T\n",
    "print acc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16fb87b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(acc_all)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52755907491201603"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(SOacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53692539188273758"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(ISpec_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65345809825715107"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(PSpec_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75005832890119217"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(DSpec_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('results.csv', acc_all, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global model simulations\n",
    "Train on increasing number of healthy subjects (from 1 to 11) and test on 1 CBR patient. Run Nruns times by randomzing subjects in each run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Healthy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 2 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 3 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 4 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 5 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 6 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 7 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 8 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 9 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 10 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 11 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "Elapsed time=59726.32 secs\n"
     ]
    }
   ],
   "source": [
    "col_names = HealthyData.column_names()\n",
    "label_cols = col_names[-1:] #the : is used to return a list with one element \n",
    "feature_cols = col_names[2:-1]\n",
    "\n",
    "Nruns = 1000 #total # of runs\n",
    "Ntrain = len(HealthyData['SubjID'].unique()) #the total number of healthy to train on\n",
    "Bacc_all = np.zeros((Nruns,Ntrain)) #contains the Bacc for each run \n",
    "\n",
    "t0 = time.time()\n",
    "#loop through num subj to train on\n",
    "for n in range(Ntrain):\n",
    "    print 'train on {} subjects'.format(n+1)\n",
    "    for run in range(1,Nruns+1):\n",
    "        if run%100 == 0:\n",
    "            print 'run={}/{}'.format(run,Nruns)       \n",
    "        #pick n subj to train \n",
    "        np.random.shuffle(HealthyCodes)\n",
    "        subjtrain = HealthyCodes[0:n+1]\n",
    "        train = HealthyData.filter_by(subjtrain,'SubjID')\n",
    "        test = np.random.shuffle(PatientCodes)\n",
    "        subjtest = PatientCodes[0] #pick one subj to test\n",
    "        test = CBRData.filter_by(subjtest,'SubjID')\n",
    "        #print 'Run=%s, Train on subj %s, test on patient %s'%(run,train['SubjID'].unique(),test['SubjID'].unique())\n",
    "\n",
    "        Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "        ytrain = train.select_columns(label_cols).to_numpy()\n",
    "        ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "        Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "        ytest = test.select_columns(label_cols).to_numpy()\n",
    "        ytest = ytest.reshape(-1)\n",
    "\n",
    "        RF = RandomForestClassifier(n_estimators=50)\n",
    "        RF = RF.fit(Xtrain,ytrain)\n",
    "        ypred = RF.predict(Xtest)\n",
    "\n",
    "        #acc = sum(ypred == ytest)/len(ytest)\n",
    "        #balanced accuracy for current run\n",
    "        Bacc_all[run-1,n],acc_class = Balanced_acc(ypred,ytest)\n",
    "        #print 'Bacc = {:.2f}'.format(Bacc_all[run,n])\n",
    "\n",
    "t1 = time.time()\n",
    "print 'Elapsed time=%.2f secs'%(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('results_GlobalH.csv', Bacc_all, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Patients Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 2 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 3 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 4 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 5 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 6 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 7 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 8 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 9 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "Elapsed time=8274.13 secs\n"
     ]
    }
   ],
   "source": [
    "col_names = SCOData.column_names()\n",
    "label_cols = col_names[-1:] #the : is used to return a list with one element \n",
    "feature_cols = col_names[2:-1]\n",
    "\n",
    "Nruns = 100 #total # of runs\n",
    "Ntrain = len(SCOData['SubjID'].unique()) #the total number of patients (SCO)\n",
    "Bacc_all = np.zeros((Nruns,Ntrain-1)) #contains the Bacc for each run \n",
    "\n",
    "t0 = time.time()\n",
    "#loop through num subj to train on\n",
    "for n in range(Ntrain-1): #-1 as one patient is out for test\n",
    "    print 'train on {} subjects'.format(n+1)\n",
    "    for run in range(1,Nruns+1):\n",
    "        if run%10 == 0:\n",
    "            print 'run={}/{}'.format(run,Nruns)       \n",
    "        #pick n subj to train (use last for test)\n",
    "        np.random.shuffle(PatientCodes)\n",
    "        subjtrain = PatientCodes[0:n+1]\n",
    "        train = SCOData.filter_by(subjtrain,'SubjID')\n",
    "        subjtest = PatientCodes[n+1] #pick one patient to test (the last, not in train)\n",
    "        test = CBRData.filter_by(subjtest,'SubjID')\n",
    "        #print 'Run=%s, Train on subj %s, test on patient %s'%(run,train['SubjID'].unique(),test['SubjID'].unique())\n",
    "\n",
    "        Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "        ytrain = train.select_columns(label_cols).to_numpy()\n",
    "        ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "        Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "        ytest = test.select_columns(label_cols).to_numpy()\n",
    "        ytest = ytest.reshape(-1)\n",
    "\n",
    "        RF = RandomForestClassifier(n_estimators=100)\n",
    "        RF = RF.fit(Xtrain,ytrain)\n",
    "        ypred = RF.predict(Xtest)\n",
    "\n",
    "        #acc = sum(ypred == ytest)/len(ytest)\n",
    "        #balanced accuracy for current run\n",
    "        Bacc_all[run-1,n],acc_class = Balanced_acc(ypred,ytest)\n",
    "        #print 'Bacc = {:.2f}'.format(Bacc_all[run-1,n])\n",
    "t1 = time.time()\n",
    "print 'Elapsed time=%.2f secs'%(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('results_GlobalP.csv', Bacc_all, delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

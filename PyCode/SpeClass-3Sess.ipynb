{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import graphlab\n",
    "import scipy #to save mat files\n",
    "import time  #to time code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#balanced accuracy\n",
    "def Balanced_acc(ypred,ytest):\n",
    "    acc_c = 0\n",
    "    acc_class = np.zeros(5) #the accuracy per class\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "        acc_class[c] = sum(correct)/len(correct)\n",
    "\n",
    "    Bacc = acc_c/len(np.unique(ytest))\n",
    "    return Bacc,acc_class\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(5)\n",
    "    plt.xticks(tick_marks, ['Sit','StairsDw','StairsUp','Stand','Walk'], rotation=45)\n",
    "    plt.yticks(tick_marks, ['Sit','StairsDw','StairsUp','Stand','Walk'])\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def prec_rec(cmat):\n",
    "    tpfp = cmat.sum(axis=1)\n",
    "    tpfn = cmat.sum(axis=0)\n",
    "    prec = cmat.diagonal()/tpfp\n",
    "    recall = cmat.diagonal()/tpfn\n",
    "    return prec,recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to llonini@ricres.org and will expire on October 14, 2017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\llonini\\AppData\\Local\\Temp\\graphlab_server_1476593799.log.0\n"
     ]
    }
   ],
   "source": [
    "HealthyData = graphlab.SFrame.read_csv('../../Datasets/Cbrace/HealthyData.csv',verbose=False)\n",
    "CBRData = graphlab.SFrame.read_csv('../../Datasets/Cbrace/CBRData3Sess.csv',verbose=False)\n",
    "SCOData = graphlab.SFrame.read_csv('../../Datasets/Cbrace/SCOData3Sess.csv',verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51 52 53 54 55 56 57 58 59 60 61]\n",
      "[ 1  2  5  6  8 11 14 15 16 19 24]\n"
     ]
    }
   ],
   "source": [
    "HealthyCodes = HealthyData['SubjID'].unique()\n",
    "HealthyCodes = HealthyCodes.sort()\n",
    "HealthyCodes = HealthyCodes.to_numpy()\n",
    "print HealthyCodes\n",
    "PatientCodes = CBRData['SubjID'].unique()\n",
    "PatientCodes = PatientCodes.sort()\n",
    "PatientCodes = PatientCodes.to_numpy()\n",
    "print PatientCodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Healthy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on Patient 1, Train samples=8375, Test samples=1288, Nclass test=5\n",
      "BAcc = 0.51\n",
      "Test on Patient 2, Train samples=8375, Test samples=991, Nclass test=5\n",
      "BAcc = 0.32\n",
      "Test on Patient 5, Train samples=8375, Test samples=1358, Nclass test=5\n",
      "BAcc = 0.42\n",
      "Test on Patient 6, Train samples=8375, Test samples=2246, Nclass test=5\n",
      "BAcc = 0.60\n",
      "Test on Patient 8, Train samples=8375, Test samples=856, Nclass test=3\n",
      "BAcc = 0.35\n",
      "Test on Patient 11, Train samples=8375, Test samples=1207, Nclass test=5\n",
      "BAcc = 0.50\n",
      "Test on Patient 14, Train samples=8375, Test samples=1778, Nclass test=5\n",
      "BAcc = 0.58\n",
      "Test on Patient 15, Train samples=8375, Test samples=3177, Nclass test=5\n",
      "BAcc = 0.46\n",
      "Test on Patient 16, Train samples=8375, Test samples=1126, Nclass test=5\n",
      "BAcc = 0.53\n",
      "Test on Patient 19, Train samples=8375, Test samples=1020, Nclass test=3\n",
      "BAcc = 0.59\n",
      "Test on Patient 24, Train samples=8375, Test samples=1449, Nclass test=5\n",
      "BAcc = 0.60\n",
      "\n",
      "median Bacc - Healthy model = 0.506258192276\n"
     ]
    }
   ],
   "source": [
    "col_names = HealthyData.column_names()\n",
    "label_cols = col_names[-1:] #the : is used to return a list with one element \n",
    "feature_cols = col_names[2:-1]\n",
    "\n",
    "Xtrain = HealthyData.select_columns(feature_cols).to_numpy()\n",
    "ytrain = HealthyData.select_columns(label_cols).to_numpy()\n",
    "ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=10,random_state=0)\n",
    "RF = RF.fit(Xtrain,ytrain)\n",
    "\n",
    "#test on each patient (CBR)\n",
    "SOacc = np.zeros(len(PatientCodes))\n",
    "acc_class_subj = [] #accuracy per class for each subject\n",
    "cmat_H = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_H = {} \n",
    "recall_H ={}\n",
    "k = 0\n",
    "\n",
    "for s in PatientCodes:\n",
    "    test = CBRData[(CBRData['SubjID'] == s)]\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "    print 'Test on Patient %s, Train samples=%s, Test samples=%s, Nclass test=%s'%(s,len(ytrain),len(ytest),Nclasses)\n",
    "    ypred = RF.predict(Xtest)\n",
    "\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #SOacc[k] = acc\n",
    "\n",
    "    #balanced accuracy\n",
    "    SOacc[k],acc_class = Balanced_acc(ypred,ytest)\n",
    "    acc_class_subj.append(acc_class)  \n",
    "    \n",
    "    #confusion matrix\n",
    "    cmat = confusion_matrix(ytest, ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "    prec,recall = prec_rec(cmat)\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(np.array(s)) #subj code\n",
    "    cmat_H.update({key:cmat})\n",
    "    prec_H.update({s:prec})\n",
    "    recall_H.update({s:recall})\n",
    "    \n",
    "    print 'BAcc = {:.2f}'.format(SOacc[k])\n",
    "    k = k+1\n",
    "\n",
    "print '\\nmedian Bacc - Healthy model = %s'%np.median(SOacc)\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_H_mean = np.nanmean(np.asarray(prec_H.values()),axis=0)\n",
    "rec_H_mean = np.nanmean(np.asarray(recall_H.values()),axis=0)\n",
    "#acc_class_subj_mean = np.nanmean(acc_class_subj,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save data\n",
    "#save the dict to matlab format \n",
    "scipy.io.savemat('cmatHealthy',cmat_H)\n",
    "np.savetxt('precisionHealthy.csv', prec_H_mean, delimiter=',') \n",
    "np.savetxt('recallHealthy.csv', rec_H_mean, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global model SCO (Leave one subject out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Nclass train = 5, Nclass test = 5, Nsamples train = 16679.0, Global SCO - BAcc = 0.57\n",
      "Patient 2, Nclass train = 5, Nclass test = 5, Nsamples train = 16200.0, Global SCO - BAcc = 0.51\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-889efe36c98c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mNclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#How many activities we have for this patient in test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mXtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mytrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mytrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/luca/anaconda/lib/python2.7/site-packages/graphlab/data_structures/sframe.pyc\u001b[0m in \u001b[0;36mto_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2939\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mHAS_NUMPY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'numpy is not installed.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2941\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/luca/anaconda/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \"\"\"\n\u001b[0;32m--> 474\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/luca/anaconda/lib/python2.7/site-packages/graphlab/data_structures/sarray.pyc\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlength\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \"\"\"\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/luca/anaconda/lib/python2.7/site-packages/graphlab/data_structures/sarray.pyc\u001b[0m in \u001b[0;36msize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1297\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0msize\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m         \"\"\"\n\u001b[0;32m-> 1299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__proxy__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ISpec_acc = np.zeros(len(PatientCodes)) \n",
    "Nsamples = np.zeros(len(PatientCodes))\n",
    "acc_class_subj = [] #accuracy per class for each subject\n",
    "\n",
    "cmat_ISpec = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_ISpec = {} \n",
    "recall_ISpec ={}\n",
    "\n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = SCOData[(SCOData['SubjID'] != s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s)] \n",
    "    Nclasstrain = len(train['Label'].unique())\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    Nsamples[k] = ytrain.shape[0]\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=10,random_state=0)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    ISpec_acc[k],acc_class = Balanced_acc(ypred,ytest)\n",
    "    acc_class_subj.append(acc_class)\n",
    "    \n",
    "    #confusion matrix\n",
    "    cmat = confusion_matrix(ytest, ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "    prec,recall = prec_rec(cmat)\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(np.array(s)) #subj code\n",
    "    cmat_ISpec.update({key:cmat})\n",
    "    prec_ISpec.update({s:prec})\n",
    "    recall_ISpec.update({s:recall})\n",
    "\n",
    "    print 'Patient {}, Nclass train = {}, Nclass test = {}, Nsamples train = {}, Global SCO - BAcc = {:.2f}'.format(s,Nclasstrain,Nclasses,Nsamples[k],ISpec_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Median BAcc - Impairment Specific (SCO) = %s'%np.median(ISpec_acc)\n",
    "print 'Avg train size = {}'.format(np.mean(Nsamples))\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_ISpec_mean = np.nanmean(np.asarray(prec_ISpec.values()),axis=0)\n",
    "rec_ISpec_mean = np.nanmean(np.asarray(recall_ISpec.values()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save the dict to matlab format \n",
    "scipy.io.savemat('cmatISpec',cmat_ISpec)\n",
    "np.savetxt('precisionISpec.csv', prec_ISpec_mean, delimiter=',') \n",
    "np.savetxt('recallISpec.csv', rec_ISpec_mean, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global model CBR (Leave one subject out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Nclass train = 5, Nclass test = 5, Nsamples train = 15208.0, Global SCO - BAcc = 0.63\n",
      "Patient 2, Nclass train = 5, Nclass test = 5, Nsamples train = 15505.0, Global SCO - BAcc = 0.48\n",
      "Patient 5, Nclass train = 5, Nclass test = 5, Nsamples train = 15138.0, Global SCO - BAcc = 0.52\n",
      "Patient 6, Nclass train = 5, Nclass test = 5, Nsamples train = 14250.0, Global SCO - BAcc = 0.59\n",
      "Patient 8, Nclass train = 5, Nclass test = 3, Nsamples train = 15640.0, Global SCO - BAcc = 0.62\n",
      "Patient 11, Nclass train = 5, Nclass test = 5, Nsamples train = 15289.0, Global SCO - BAcc = 0.57\n",
      "Patient 14, Nclass train = 5, Nclass test = 5, Nsamples train = 14718.0, Global SCO - BAcc = 0.60\n",
      "Patient 15, Nclass train = 5, Nclass test = 5, Nsamples train = 13319.0, Global SCO - BAcc = 0.67\n",
      "Patient 16, Nclass train = 5, Nclass test = 5, Nsamples train = 15370.0, Global SCO - BAcc = 0.59\n",
      "Patient 19, Nclass train = 5, Nclass test = 3, Nsamples train = 15476.0, Global SCO - BAcc = 0.90\n",
      "Patient 24, Nclass train = 5, Nclass test = 5, Nsamples train = 15047.0, Global SCO - BAcc = 0.67\n",
      "Median BAcc - Global CBR model = 0.602154346755\n",
      "Avg train size = 14996.3636364\n"
     ]
    }
   ],
   "source": [
    "ISpecCBR_acc = np.zeros(len(PatientCodes))\n",
    "Nsamples = np.zeros(len(PatientCodes))\n",
    "acc_class_subj = [] #accuracy per class for each subject\n",
    "\n",
    "cmat_ISpecCBR = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_ISpecCBR = {} \n",
    "recall_ISpecCBR ={}\n",
    "\n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = CBRData[(CBRData['SubjID'] != s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s)] #test on 3 CBR sessions\n",
    "    Nclasstrain = len(train['Label'].unique())\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    Nsamples[k] = ytrain.shape[0]\n",
    "\n",
    "    RF = RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    ISpecCBR_acc[k],acc_class = Balanced_acc(ypred,ytest)\n",
    "    acc_class_subj.append(acc_class)   \n",
    "    \n",
    "    #confusion matrix\n",
    "    cmat = confusion_matrix(ytest, ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "    prec,recall = prec_rec(cmat)\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(np.array(s)) #subj code\n",
    "    cmat_ISpecCBR.update({key:cmat})\n",
    "    prec_ISpecCBR.update({s:prec})\n",
    "    recall_ISpecCBR.update({s:recall})\n",
    "\n",
    "    print 'Patient {}, Nclass train = {}, Nclass test = {}, Nsamples train = {}, Global SCO - BAcc = {:.2f}'.format(s,Nclasstrain,Nclasses,Nsamples[k],ISpecCBR_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Median BAcc - Global CBR model = %s'%np.median(ISpecCBR_acc)\n",
    "print 'Avg train size = {}'.format(np.mean(Nsamples))\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_ISpecCBR_mean = np.nanmean(np.asarray(prec_ISpecCBR.values()),axis=0)\n",
    "rec_ISpecCBR_mean = np.nanmean(np.asarray(recall_ISpecCBR.values()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the dict to matlab format \n",
    "scipy.io.savemat('cmatISpecCBR',cmat_ISpecCBR)\n",
    "np.savetxt('precisionISpecCBR.csv', prec_ISpecCBR_mean, delimiter=',') \n",
    "np.savetxt('recallISpecCBR.csv', rec_ISpecCBR_mean, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal SCO (Patient Specific model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Nclass train = 5, Nclass test = 5,  Nsamples train = 935.0, Personal SCO - BAcc = 0.72\n",
      "Patient 2, Nclass train = 5, Nclass test = 5,  Nsamples train = 1414.0, Personal SCO - BAcc = 0.55\n",
      "Patient 5, Nclass train = 5, Nclass test = 5,  Nsamples train = 2376.0, Personal SCO - BAcc = 0.65\n",
      "Patient 6, Nclass train = 5, Nclass test = 5,  Nsamples train = 1076.0, Personal SCO - BAcc = 0.74\n",
      "Patient 8, Nclass train = 5, Nclass test = 3,  Nsamples train = 2182.0, Personal SCO - BAcc = 0.69\n",
      "Patient 11, Nclass train = 5, Nclass test = 5,  Nsamples train = 1636.0, Personal SCO - BAcc = 0.43\n",
      "Patient 14, Nclass train = 5, Nclass test = 5,  Nsamples train = 1606.0, Personal SCO - BAcc = 0.48\n",
      "Patient 15, Nclass train = 5, Nclass test = 5,  Nsamples train = 1863.0, Personal SCO - BAcc = 0.44\n",
      "Patient 16, Nclass train = 5, Nclass test = 5,  Nsamples train = 2184.0, Personal SCO - BAcc = 0.46\n",
      "Patient 19, Nclass train = 5, Nclass test = 3,  Nsamples train = 1255.0, Personal SCO - BAcc = 0.73\n",
      "Patient 24, Nclass train = 5, Nclass test = 5,  Nsamples train = 1087.0, Personal SCO - BAcc = 0.75\n",
      "Median BAcc - Patient Specific (SCO) = 0.65157867467\n",
      "Avg train size = 1601.27272727\n"
     ]
    }
   ],
   "source": [
    "PSpec_acc = np.zeros(len(PatientCodes)) \n",
    "Nsamples = np.zeros(len(PatientCodes))\n",
    "acc_class_subj = [] #accuracy per class for each subject\n",
    "\n",
    "cmat_PSpec = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_PSpec = {} \n",
    "recall_PSpec ={}\n",
    "\n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = SCOData[(SCOData['SubjID'] == s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s)]\n",
    "    Nclasstrain = len(train['Label'].unique())\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    Nsamples[k] = ytrain.shape[0]\n",
    "\n",
    "    RF = RandomForestClassifier(n_estimators=50,random_state=0)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    PSpec_acc[k],acc_class = Balanced_acc(ypred,ytest)\n",
    "    \n",
    "    #confusion matrix\n",
    "    cmat = confusion_matrix(ytest, ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "    prec,recall = prec_rec(cmat)\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(np.array(s)) #subj code\n",
    "    cmat_PSpec.update({key:cmat})\n",
    "    prec_PSpec.update({s:prec})\n",
    "    recall_PSpec.update({s:recall})\n",
    "    \n",
    "    print 'Patient {}, Nclass train = {}, Nclass test = {},  Nsamples train = {}, Personal SCO - BAcc = {:.2f}'.format(s,Nclasstrain,Nclasses,Nsamples[k],PSpec_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Median BAcc - Patient Specific (SCO) = %s'%np.median(PSpec_acc)\n",
    "print 'Avg train size = {}'.format(np.mean(Nsamples))\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_PSpec_mean = np.nanmean(np.asarray(prec_PSpec.values()),axis=0)\n",
    "rec_PSpec_mean = np.nanmean(np.asarray(recall_PSpec.values()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the dict to matlab format \n",
    "scipy.io.savemat('cmatPSpec',cmat_PSpec)\n",
    "np.savetxt('precisionPSpec.csv', prec_PSpec_mean, delimiter=',') \n",
    "np.savetxt('recallPSpec.csv', rec_PSpec_mean, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal CBR (Patient and Device specific model) \n",
    "Leave One Session Out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nclass train = 5, Nclass test =5, BAcc = 0.77\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.82\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.87\n",
      "Patient 1, Device Specific model - BAcc = 0.82\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.76\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.51\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.73\n",
      "Patient 2, Device Specific model - BAcc = 0.67\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.78\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.55\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.59\n",
      "Patient 5, Device Specific model - BAcc = 0.64\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.61\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.75\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.84\n",
      "Patient 6, Device Specific model - BAcc = 0.73\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.93\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.70\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.97\n",
      "Patient 8, Device Specific model - BAcc = 0.87\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.41\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.59\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.47\n",
      "Patient 11, Device Specific model - BAcc = 0.49\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.69\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.74\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.87\n",
      "Patient 14, Device Specific model - BAcc = 0.76\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.55\n",
      "Nclass train = 5, Nclass test =3, BAcc = 0.97\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.60\n",
      "Patient 15, Device Specific model - BAcc = 0.71\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.62\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.62\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.84\n",
      "Patient 16, Device Specific model - BAcc = 0.70\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.54\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.97\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.78\n",
      "Patient 19, Device Specific model - BAcc = 0.76\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.84\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.85\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.62\n",
      "Patient 24, Device Specific model - BAcc = 0.77\n",
      "Median BAcc - Device Specific (CBR) = 0.732441020271\n",
      "Avg train size = 999.757575758\n"
     ]
    }
   ],
   "source": [
    "DSpec_acc = np.zeros(len(PatientCodes)) \n",
    "Nsamples = np.zeros(len(PatientCodes))\n",
    "Nsessions = 3\n",
    "\n",
    "cmat_DSpec = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_DSpec = {} \n",
    "recall_DSpec ={}\n",
    "k = 0\n",
    "\n",
    "for s in PatientCodes:\n",
    "    cmat = np.zeros((5,5)) #temporary arrays to store cmat, prec and recall in each session\n",
    "    prec = np.zeros(5)\n",
    "    recall = np.zeros(5)\n",
    "\n",
    "    data =  CBRData[(CBRData['SubjID'] == s)] \n",
    "    Bacc = np.zeros(Nsessions)\n",
    "    for session in range(1,Nsessions+1):\n",
    "                  \n",
    "        test = data[data['Session'] == session]\n",
    "        train = data[data['Session'] != session]\n",
    "        Nclasstrain = len(train['Label'].unique())\n",
    "        Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "        Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "        ytrain = train.select_columns(label_cols).to_numpy()\n",
    "        ytrain = ytrain.reshape(-1)\n",
    "        Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "        ytest = test.select_columns(label_cols).to_numpy()\n",
    "        ytest = ytest.reshape(-1)\n",
    "        Nsamples[k] = Nsamples[k]+ytrain.shape[0]\n",
    "\n",
    "        RF = RandomForestClassifier(n_estimators=50,random_state=0)\n",
    "        RF = RF.fit(Xtrain,ytrain)\n",
    "        ypred = RF.predict(Xtest)\n",
    "        #acc = sum(ypred == ytest)/len(ytest)\n",
    "        #balanced accuracy on each session\n",
    "        Bacc[session-1],acc_class = Balanced_acc(ypred,ytest)\n",
    "        print 'Nclass train = {}, Nclass test ={}, BAcc = {:.2f}'.format(Nclasstrain,Nclasses,Bacc[session-1])\n",
    "        \n",
    "        #confusion matrix, prec and recall in each session\n",
    "        cmat_tmp = confusion_matrix(ytest,ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "        cmat += cmat_tmp\n",
    "        pr,re = prec_rec(cmat_tmp)\n",
    "        prec += pr\n",
    "        recall += re\n",
    "\n",
    "    DSpec_acc[k] = Bacc.mean() #the CV BAcc on 3 sessions \n",
    "    Nsamples[k] = Nsamples[k]/len(range(1,Nsessions+1)) #mean number of samples across sessions    \n",
    "    #mean confusion matrix (instances), precision and recall on 3 sessions\n",
    "    avgcmat = cmat/Nsessions\n",
    "    prec = prec/Nsessions\n",
    "    recall = recall/Nsessions\n",
    "\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(np.array(s)) #subj code\n",
    "    cmat_DSpec.update({key:avgcmat})     #the confusion matrix with instances from the 4 sessions\n",
    "    prec_DSpec.update({s:prec})\n",
    "    recall_DSpec.update({s:recall})\n",
    "   \n",
    "    print 'Patient {}, Device Specific model - BAcc = {:.2f}'.format(s,DSpec_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Median BAcc - Device Specific (CBR) = %s'%(np.median(DSpec_acc))\n",
    "print 'Avg train size = {}'.format(np.mean(Nsamples))\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_DSpec_mean = np.nanmean(np.asarray(prec_DSpec.values()),axis=0)\n",
    "rec_DSpec_mean = np.nanmean(np.asarray(recall_DSpec.values()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save the dict to matlab format \n",
    "scipy.io.savemat('cmatDSpec',cmat_DSpec)\n",
    "np.savetxt('precisionDSpec.csv', prec_DSpec_mean, delimiter=',') \n",
    "np.savetxt('recallDSpec.csv', rec_DSpec_mean, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble results for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ISpecCBR_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-1ba350ba238d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0macc_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSOacc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mISpec_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mISpecCBR_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPSpec_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDSpec_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0macc_all\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ISpecCBR_acc' is not defined"
     ]
    }
   ],
   "source": [
    "acc_all=np.vstack((SOacc,ISpec_acc,ISpecCBR_acc,PSpec_acc,DSpec_acc)).T\n",
    "print acc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128650e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(acc_all)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53400055983576222"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(SOacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55567333631468108"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(ISpec_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6021543467550432"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(ISpecCBR_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65157867467006247"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(PSpec_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73244102027087032"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(DSpec_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('results.csv', acc_all, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on Patient 1, Train samples=8375, Test samples=1288, Nclass test=5\n",
      "BAcc = 0.52\n",
      "Test on Patient 2, Train samples=8375, Test samples=991, Nclass test=5\n",
      "BAcc = 0.39\n",
      "Test on Patient 5, Train samples=8375, Test samples=1358, Nclass test=5\n",
      "BAcc = 0.45\n",
      "Test on Patient 6, Train samples=8375, Test samples=2246, Nclass test=5\n",
      "BAcc = 0.60\n",
      "Test on Patient 8, Train samples=8375, Test samples=856, Nclass test=3\n",
      "BAcc = 0.36\n",
      "Test on Patient 11, Train samples=8375, Test samples=1207, Nclass test=5\n",
      "BAcc = 0.52\n",
      "Test on Patient 14, Train samples=8375, Test samples=1778, Nclass test=5\n",
      "BAcc = 0.53\n",
      "Test on Patient 15, Train samples=8375, Test samples=3177, Nclass test=5\n",
      "BAcc = 0.48\n",
      "Test on Patient 16, Train samples=8375, Test samples=1126, Nclass test=5\n",
      "BAcc = 0.53\n",
      "Test on Patient 19, Train samples=8375, Test samples=1020, Nclass test=3\n",
      "BAcc = 0.64\n",
      "Test on Patient 24, Train samples=8375, Test samples=1449, Nclass test=5\n",
      "BAcc = 0.64\n",
      "\n",
      "median Bacc - Healthy model = 0.519083682588\n"
     ]
    }
   ],
   "source": [
    "col_names = HealthyData.column_names()\n",
    "label_cols = col_names[-1:] #the : is used to return a list with one element \n",
    "feature_cols = col_names[2:-1]\n",
    "\n",
    "Xtrain = HealthyData.select_columns(feature_cols).to_numpy()\n",
    "ytrain = HealthyData.select_columns(label_cols).to_numpy()\n",
    "ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100,random_state=0)\n",
    "clf = clf.fit(Xtrain,ytrain)\n",
    "\n",
    "#test on each patient (CBR)\n",
    "SOacc = np.zeros(len(PatientCodes))\n",
    "acc_class_subj = [] #accuracy per class for each subject\n",
    "cmat_H = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_H = {} \n",
    "recall_H ={}\n",
    "k = 0\n",
    "\n",
    "for s in PatientCodes:\n",
    "    test = CBRData[(CBRData['SubjID'] == s)]\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "    print 'Test on Patient %s, Train samples=%s, Test samples=%s, Nclass test=%s'%(s,len(ytrain),len(ytest),Nclasses)\n",
    "    ypred = clf.predict(Xtest)\n",
    "\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #SOacc[k] = acc\n",
    "\n",
    "    #balanced accuracy\n",
    "    SOacc[k],acc_class = Balanced_acc(ypred,ytest)\n",
    "    acc_class_subj.append(acc_class)  \n",
    "    \n",
    "    #confusion matrix\n",
    "    cmat = confusion_matrix(ytest, ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "    prec,recall = prec_rec(cmat)\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(np.array(s)) #subj code\n",
    "    cmat_H.update({key:cmat})\n",
    "    prec_H.update({s:prec})\n",
    "    recall_H.update({s:recall})\n",
    "    \n",
    "    print 'BAcc = {:.2f}'.format(SOacc[k])\n",
    "    k = k+1\n",
    "\n",
    "print '\\nmedian Bacc - Healthy model = %s'%np.median(SOacc)\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_H_mean = np.nanmean(np.asarray(prec_H.values()),axis=0)\n",
    "rec_H_mean = np.nanmean(np.asarray(recall_H.values()),axis=0)\n",
    "#acc_class_subj_mean = np.nanmean(acc_class_subj,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global model simulations\n",
    "Train on increasing number of healthy subjects (from 1 to 11) and test on 1 CBR patient. Run Nruns times by randomzing subjects in each run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Healthy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 2 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 3 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 4 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 5 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 6 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 7 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 8 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 9 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 10 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 11 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "Elapsed time=29523.37 secs\n"
     ]
    }
   ],
   "source": [
    "col_names = HealthyData.column_names()\n",
    "label_cols = col_names[-1:] #the : is used to return a list with one element \n",
    "feature_cols = col_names[2:-1]\n",
    "\n",
    "Nruns = 1000 #total # of runs\n",
    "Ntrain = len(HealthyData['SubjID'].unique()) #the total number of healthy to train on\n",
    "Bacc_all = np.zeros((Nruns,Ntrain)) #contains the Bacc for each run \n",
    "\n",
    "t0 = time.time()\n",
    "#loop through num subj to train on\n",
    "for n in range(Ntrain):\n",
    "    print 'train on {} subjects'.format(n+1)\n",
    "    for run in range(1,Nruns+1):\n",
    "        if run%100 == 0:\n",
    "            print 'run={}/{}'.format(run,Nruns)       \n",
    "        #pick n subj to train \n",
    "        np.random.shuffle(HealthyCodes)\n",
    "        subjtrain = HealthyCodes[0:n+1]\n",
    "        train = HealthyData.filter_by(subjtrain,'SubjID')\n",
    "        test = np.random.shuffle(PatientCodes)\n",
    "        subjtest = PatientCodes[0] #pick one subj to test\n",
    "        test = CBRData.filter_by(subjtest,'SubjID')\n",
    "        #print 'Run=%s, Train on subj %s, test on patient %s'%(run,train['SubjID'].unique(),test['SubjID'].unique())\n",
    "\n",
    "        Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "        ytrain = train.select_columns(label_cols).to_numpy()\n",
    "        ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "        Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "        ytest = test.select_columns(label_cols).to_numpy()\n",
    "        ytest = ytest.reshape(-1)\n",
    "\n",
    "        RF = RandomForestClassifier(n_estimators=10)\n",
    "        RF = RF.fit(Xtrain,ytrain)\n",
    "        ypred = RF.predict(Xtest)\n",
    "\n",
    "        #acc = sum(ypred == ytest)/len(ytest)\n",
    "        #balanced accuracy for current run\n",
    "        Bacc_all[run-1,n],acc_class = Balanced_acc(ypred,ytest)\n",
    "        #print 'Bacc = {:.2f}'.format(Bacc_all[run,n])\n",
    "\n",
    "t1 = time.time()\n",
    "print 'Elapsed time=%.2f secs'%(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('results_GlobalH.csv', Bacc_all, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Global SCO Model simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 2 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 3 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 4 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 5 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 6 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 7 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 8 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 9 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 10 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "Elapsed time=96572.86 secs\n"
     ]
    }
   ],
   "source": [
    "col_names = SCOData.column_names()\n",
    "label_cols = col_names[-1:] #the : is used to return a list with one element \n",
    "feature_cols = col_names[2:-1]\n",
    "\n",
    "Nruns = 1000 #total # of runs\n",
    "Ntrain = len(SCOData['SubjID'].unique()) #the total number of patients (SCO)\n",
    "Bacc_all = np.zeros((Nruns,Ntrain-1)) #contains the Bacc for each run \n",
    "\n",
    "t0 = time.time()\n",
    "#loop through num subj to train on\n",
    "for n in range(Ntrain-1): #-1 as one patient is out for test\n",
    "    print 'train on {} subjects'.format(n+1)\n",
    "    for run in range(1,Nruns+1):\n",
    "        if run%100 == 0:\n",
    "            print 'run={}/{}'.format(run,Nruns)       \n",
    "        #pick n subj to train (use last for test)\n",
    "        np.random.shuffle(PatientCodes)\n",
    "        subjtrain = PatientCodes[0:n+1]\n",
    "        train = SCOData.filter_by(subjtrain,'SubjID')\n",
    "        subjtest = PatientCodes[n+1] #pick one patient to test (the last, not in train)\n",
    "        test = CBRData.filter_by(subjtest,'SubjID')\n",
    "        #print 'Run=%s, Train on subj %s, test on patient %s'%(run,train['SubjID'].unique(),test['SubjID'].unique())\n",
    "\n",
    "        Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "        ytrain = train.select_columns(label_cols).to_numpy()\n",
    "        ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "        Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "        ytest = test.select_columns(label_cols).to_numpy()\n",
    "        ytest = ytest.reshape(-1)\n",
    "\n",
    "        RF = RandomForestClassifier(n_estimators=10)\n",
    "        RF = RF.fit(Xtrain,ytrain)\n",
    "        ypred = RF.predict(Xtest)\n",
    "\n",
    "        #acc = sum(ypred == ytest)/len(ytest)\n",
    "        #balanced accuracy for current run\n",
    "        Bacc_all[run-1,n],acc_class = Balanced_acc(ypred,ytest)\n",
    "        #print 'Bacc = {:.2f}'.format(Bacc_all[run-1,n])\n",
    "t1 = time.time()\n",
    "print 'Elapsed time=%.2f secs'%(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('results_GlobalP.csv', Bacc_all, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Global CBR Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 2 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 3 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 4 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 5 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 6 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 7 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 8 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 9 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 10 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "Elapsed time=38237.74 secs\n"
     ]
    }
   ],
   "source": [
    "col_names = CBRData.column_names()\n",
    "label_cols = col_names[-1:] #the : is used to return a list with one element \n",
    "feature_cols = col_names[2:-1]\n",
    "\n",
    "Nruns = 1000 #total # of runs\n",
    "Ntrain = len(CBRData['SubjID'].unique()) #the total number of patients (CBR)\n",
    "Bacc_all = np.zeros((Nruns,Ntrain-1)) #contains the Bacc for each run \n",
    "\n",
    "t0 = time.time()\n",
    "#loop through num subj to train on\n",
    "for n in range(Ntrain-1): #-1 as one patient is out for test\n",
    "    print 'train on {} subjects'.format(n+1)\n",
    "    for run in range(1,Nruns+1):\n",
    "        if run%100 == 0:\n",
    "            print 'run={}/{}'.format(run,Nruns)       \n",
    "        #pick n subj to train (use last for test)\n",
    "        np.random.shuffle(PatientCodes)\n",
    "        subjtrain = PatientCodes[0:n+1]\n",
    "        train = CBRData.filter_by(subjtrain,'SubjID')\n",
    "        subjtest = PatientCodes[n+1] #pick one patient to test (the last, not in train)\n",
    "        test = CBRData.filter_by(subjtest,'SubjID')\n",
    "        #print 'Run=%s, Train on subj %s, test on patient %s'%(run,train['SubjID'].unique(),test['SubjID'].unique())\n",
    "\n",
    "        Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "        ytrain = train.select_columns(label_cols).to_numpy()\n",
    "        ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "        Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "        ytest = test.select_columns(label_cols).to_numpy()\n",
    "        ytest = ytest.reshape(-1)\n",
    "\n",
    "        RF = RandomForestClassifier(n_estimators=50,n_jobs=-1)\n",
    "        RF = RF.fit(Xtrain,ytrain)\n",
    "        ypred = RF.predict(Xtest)\n",
    "\n",
    "        #acc = sum(ypred == ytest)/len(ytest)\n",
    "        #balanced accuracy for current run\n",
    "        Bacc_all[run-1,n],acc_class = Balanced_acc(ypred,ytest)\n",
    "        #print 'Bacc = {:.2f}'.format(Bacc_all[run-1,n])\n",
    "t1 = time.time()\n",
    "print 'Elapsed time=%.2f secs'%(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('results_GlobalP_CBR.csv', Bacc_all, delimiter=',') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

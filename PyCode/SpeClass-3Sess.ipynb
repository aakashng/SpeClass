{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import graphlab\n",
    "import scipy #to save mat files\n",
    "import time  #to time code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#balanced accuracy\n",
    "def Balanced_acc(ypred,ytest):\n",
    "    acc_c = 0\n",
    "    acc_class = np.zeros(5) #the accuracy per class\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "        acc_class[c] = sum(correct)/len(correct)\n",
    "\n",
    "    Bacc = acc_c/len(np.unique(ytest))\n",
    "    return Bacc,acc_class\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(5)\n",
    "    plt.xticks(tick_marks, ['Sit','StairsDw','StairsUp','Stand','Walk'], rotation=45)\n",
    "    plt.yticks(tick_marks, ['Sit','StairsDw','StairsUp','Stand','Walk'])\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def prec_rec(cmat):\n",
    "    tpfp = cmat.sum(axis=1)\n",
    "    tpfn = cmat.sum(axis=0)\n",
    "    prec = cmat.diagonal()/tpfp\n",
    "    recall = cmat.diagonal()/tpfn\n",
    "    return prec,recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to llonini@ricres.org and will expire on October 14, 2017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1476807430.log\n"
     ]
    }
   ],
   "source": [
    "HealthyData = graphlab.SFrame.read_csv('../../Datasets/Cbrace/HealthyData.csv',verbose=False)\n",
    "CBRData = graphlab.SFrame.read_csv('../../Datasets/Cbrace/CBRData3Sess.csv',verbose=False)\n",
    "SCOData = graphlab.SFrame.read_csv('../../Datasets/Cbrace/SCOData3Sess.csv',verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51 52 53 54 55 56 57 58 59 60 61]\n",
      "[ 1  2  5  6  8 11 14 15 16 19 24]\n"
     ]
    }
   ],
   "source": [
    "HealthyCodes = HealthyData['SubjID'].unique()\n",
    "HealthyCodes = HealthyCodes.sort()\n",
    "HealthyCodes = HealthyCodes.to_numpy()\n",
    "print HealthyCodes\n",
    "PatientCodes = CBRData['SubjID'].unique()\n",
    "PatientCodes = PatientCodes.sort()\n",
    "PatientCodes = PatientCodes.to_numpy()\n",
    "print PatientCodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Healthy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on Patient 1, Train samples=8375, Test samples=1288, Nclass test=5\n",
      "BAcc = 0.46\n",
      "Test on Patient 2, Train samples=8375, Test samples=991, Nclass test=5\n",
      "BAcc = 0.40\n",
      "Test on Patient 5, Train samples=8375, Test samples=1358, Nclass test=5\n",
      "BAcc = 0.46\n",
      "Test on Patient 6, Train samples=8375, Test samples=2246, Nclass test=5\n",
      "BAcc = 0.58\n",
      "Test on Patient 8, Train samples=8375, Test samples=856, Nclass test=3\n",
      "BAcc = 0.36\n",
      "Test on Patient 11, Train samples=8375, Test samples=1207, Nclass test=5\n",
      "BAcc = 0.54\n",
      "Test on Patient 14, Train samples=8375, Test samples=1778, Nclass test=5\n",
      "BAcc = 0.53\n",
      "Test on Patient 15, Train samples=8375, Test samples=3177, Nclass test=5\n",
      "BAcc = 0.54\n",
      "Test on Patient 16, Train samples=8375, Test samples=1126, Nclass test=5\n",
      "BAcc = 0.53\n",
      "Test on Patient 19, Train samples=8375, Test samples=1020, Nclass test=3\n",
      "BAcc = 0.55\n",
      "Test on Patient 24, Train samples=8375, Test samples=1449, Nclass test=5\n",
      "BAcc = 0.60\n",
      "\n",
      "median Bacc - Healthy model = 0.534000559836\n"
     ]
    }
   ],
   "source": [
    "col_names = HealthyData.column_names()\n",
    "label_cols = col_names[-1:] #the : is used to return a list with one element \n",
    "feature_cols = col_names[2:-1]\n",
    "\n",
    "Xtrain = HealthyData.select_columns(feature_cols).to_numpy()\n",
    "ytrain = HealthyData.select_columns(label_cols).to_numpy()\n",
    "ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=10,random_state=0)\n",
    "RF = RF.fit(Xtrain,ytrain)\n",
    "\n",
    "#test on each patient (CBR)\n",
    "SOacc = np.zeros(len(PatientCodes))\n",
    "acc_class_subj = [] #accuracy per class for each subject\n",
    "cmat_H = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_H = {} \n",
    "recall_H ={}\n",
    "k = 0\n",
    "\n",
    "for s in PatientCodes:\n",
    "    test = CBRData[(CBRData['SubjID'] == s)]\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "    print 'Test on Patient %s, Train samples=%s, Test samples=%s, Nclass test=%s'%(s,len(ytrain),len(ytest),Nclasses)\n",
    "    ypred = RF.predict(Xtest)\n",
    "\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #SOacc[k] = acc\n",
    "\n",
    "    #balanced accuracy\n",
    "    SOacc[k],acc_class = Balanced_acc(ypred,ytest)\n",
    "    acc_class_subj.append(acc_class)  \n",
    "    \n",
    "    #confusion matrix\n",
    "    cmat = confusion_matrix(ytest, ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "    prec,recall = prec_rec(cmat)\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(np.array(s)) #subj code\n",
    "    cmat_H.update({key:cmat})\n",
    "    prec_H.update({s:prec})\n",
    "    recall_H.update({s:recall})\n",
    "    \n",
    "    print 'BAcc = {:.2f}'.format(SOacc[k])\n",
    "    k = k+1\n",
    "\n",
    "print '\\nmedian Bacc - Healthy model = %s'%np.median(SOacc)\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_H_mean = np.nanmean(np.asarray(prec_H.values()),axis=0)\n",
    "rec_H_mean = np.nanmean(np.asarray(recall_H.values()),axis=0)\n",
    "#acc_class_subj_mean = np.nanmean(acc_class_subj,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save data\n",
    "#save the dict to matlab format \n",
    "scipy.io.savemat('cmatHealthy',cmat_H)\n",
    "np.savetxt('precisionHealthy.csv', prec_H_mean, delimiter=',') \n",
    "np.savetxt('recallHealthy.csv', rec_H_mean, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global model SCO (Leave one subject out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Nclass train = 5, Nclass test = 5, Nsamples train = 16679.0, Global SCO - BAcc = 0.52\n",
      "Patient 2, Nclass train = 5, Nclass test = 5, Nsamples train = 16200.0, Global SCO - BAcc = 0.50\n",
      "Patient 5, Nclass train = 5, Nclass test = 5, Nsamples train = 15238.0, Global SCO - BAcc = 0.51\n",
      "Patient 6, Nclass train = 5, Nclass test = 5, Nsamples train = 16538.0, Global SCO - BAcc = 0.57\n",
      "Patient 8, Nclass train = 5, Nclass test = 3, Nsamples train = 15432.0, Global SCO - BAcc = 0.46\n",
      "Patient 11, Nclass train = 5, Nclass test = 5, Nsamples train = 15978.0, Global SCO - BAcc = 0.53\n",
      "Patient 14, Nclass train = 5, Nclass test = 5, Nsamples train = 16008.0, Global SCO - BAcc = 0.60\n",
      "Patient 15, Nclass train = 5, Nclass test = 5, Nsamples train = 15751.0, Global SCO - BAcc = 0.57\n",
      "Patient 16, Nclass train = 5, Nclass test = 5, Nsamples train = 15430.0, Global SCO - BAcc = 0.56\n",
      "Patient 19, Nclass train = 5, Nclass test = 3, Nsamples train = 16359.0, Global SCO - BAcc = 0.83\n",
      "Patient 24, Nclass train = 5, Nclass test = 5, Nsamples train = 16527.0, Global SCO - BAcc = 0.59\n",
      "Median BAcc - Impairment Specific (SCO) = 0.555673336315\n",
      "Avg train size = 16012.7272727\n"
     ]
    }
   ],
   "source": [
    "ISpec_acc = np.zeros(len(PatientCodes)) \n",
    "Nsamples = np.zeros(len(PatientCodes))\n",
    "acc_class_subj = [] #accuracy per class for each subject\n",
    "\n",
    "cmat_ISpec = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_ISpec = {} \n",
    "recall_ISpec ={}\n",
    "\n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = SCOData[(SCOData['SubjID'] != s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s)] \n",
    "    Nclasstrain = len(train['Label'].unique())\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    Nsamples[k] = ytrain.shape[0]\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=10,random_state=0)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    ISpec_acc[k],acc_class = Balanced_acc(ypred,ytest)\n",
    "    acc_class_subj.append(acc_class)\n",
    "    \n",
    "    #confusion matrix\n",
    "    cmat = confusion_matrix(ytest, ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "    prec,recall = prec_rec(cmat)\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(np.array(s)) #subj code\n",
    "    cmat_ISpec.update({key:cmat})\n",
    "    prec_ISpec.update({s:prec})\n",
    "    recall_ISpec.update({s:recall})\n",
    "\n",
    "    print 'Patient {}, Nclass train = {}, Nclass test = {}, Nsamples train = {}, Global SCO - BAcc = {:.2f}'.format(s,Nclasstrain,Nclasses,Nsamples[k],ISpec_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Median BAcc - Impairment Specific (SCO) = %s'%np.median(ISpec_acc)\n",
    "print 'Avg train size = {}'.format(np.mean(Nsamples))\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_ISpec_mean = np.nanmean(np.asarray(prec_ISpec.values()),axis=0)\n",
    "rec_ISpec_mean = np.nanmean(np.asarray(recall_ISpec.values()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save the dict to matlab format \n",
    "scipy.io.savemat('cmatISpec',cmat_ISpec)\n",
    "np.savetxt('precisionISpec.csv', prec_ISpec_mean, delimiter=',') \n",
    "np.savetxt('recallISpec.csv', rec_ISpec_mean, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global model CBR (Leave one subject out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Nclass train = 5, Nclass test = 5, Nsamples train = 15208.0, Global SCO - BAcc = 0.65\n",
      "Patient 2, Nclass train = 5, Nclass test = 5, Nsamples train = 15505.0, Global SCO - BAcc = 0.46\n",
      "Patient 5, Nclass train = 5, Nclass test = 5, Nsamples train = 15138.0, Global SCO - BAcc = 0.55\n",
      "Patient 6, Nclass train = 5, Nclass test = 5, Nsamples train = 14250.0, Global SCO - BAcc = 0.61\n",
      "Patient 8, Nclass train = 5, Nclass test = 3, Nsamples train = 15640.0, Global SCO - BAcc = 0.64\n",
      "Patient 11, Nclass train = 5, Nclass test = 5, Nsamples train = 15289.0, Global SCO - BAcc = 0.58\n",
      "Patient 14, Nclass train = 5, Nclass test = 5, Nsamples train = 14718.0, Global SCO - BAcc = 0.60\n",
      "Patient 15, Nclass train = 5, Nclass test = 5, Nsamples train = 13319.0, Global SCO - BAcc = 0.67\n",
      "Patient 16, Nclass train = 5, Nclass test = 5, Nsamples train = 15370.0, Global SCO - BAcc = 0.60\n",
      "Patient 19, Nclass train = 5, Nclass test = 3, Nsamples train = 15476.0, Global SCO - BAcc = 0.90\n",
      "Patient 24, Nclass train = 5, Nclass test = 5, Nsamples train = 15047.0, Global SCO - BAcc = 0.67\n",
      "Median BAcc - Global CBR model = 0.609663016541\n",
      "Avg train size = 14996.3636364\n"
     ]
    }
   ],
   "source": [
    "ISpecCBR_acc = np.zeros(len(PatientCodes))\n",
    "Nsamples = np.zeros(len(PatientCodes))\n",
    "acc_class_subj = [] #accuracy per class for each subject\n",
    "\n",
    "cmat_ISpecCBR = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_ISpecCBR = {} \n",
    "recall_ISpecCBR ={}\n",
    "\n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = CBRData[(CBRData['SubjID'] != s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s)] #test on 3 CBR sessions\n",
    "    Nclasstrain = len(train['Label'].unique())\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    Nsamples[k] = ytrain.shape[0]\n",
    "\n",
    "    RF = RandomForestClassifier(n_estimators=50,random_state=0)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    ISpecCBR_acc[k],acc_class = Balanced_acc(ypred,ytest)\n",
    "    acc_class_subj.append(acc_class)   \n",
    "    \n",
    "    #confusion matrix\n",
    "    cmat = confusion_matrix(ytest, ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "    prec,recall = prec_rec(cmat)\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(np.array(s)) #subj code\n",
    "    cmat_ISpecCBR.update({key:cmat})\n",
    "    prec_ISpecCBR.update({s:prec})\n",
    "    recall_ISpecCBR.update({s:recall})\n",
    "\n",
    "    print 'Patient {}, Nclass train = {}, Nclass test = {}, Nsamples train = {}, Global SCO - BAcc = {:.2f}'.format(s,Nclasstrain,Nclasses,Nsamples[k],ISpecCBR_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Median BAcc - Global CBR model = %s'%np.median(ISpecCBR_acc)\n",
    "print 'Avg train size = {}'.format(np.mean(Nsamples))\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_ISpecCBR_mean = np.nanmean(np.asarray(prec_ISpecCBR.values()),axis=0)\n",
    "rec_ISpecCBR_mean = np.nanmean(np.asarray(recall_ISpecCBR.values()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the dict to matlab format \n",
    "scipy.io.savemat('cmatISpecCBR',cmat_ISpecCBR)\n",
    "np.savetxt('precisionISpecCBR.csv', prec_ISpecCBR_mean, delimiter=',') \n",
    "np.savetxt('recallISpecCBR.csv', rec_ISpecCBR_mean, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal SCO (Patient Specific model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Nclass train = 5, Nclass test = 5,  Nsamples train = 935.0, Personal SCO - BAcc = 0.72\n",
      "Patient 2, Nclass train = 5, Nclass test = 5,  Nsamples train = 1414.0, Personal SCO - BAcc = 0.55\n",
      "Patient 5, Nclass train = 5, Nclass test = 5,  Nsamples train = 2376.0, Personal SCO - BAcc = 0.65\n",
      "Patient 6, Nclass train = 5, Nclass test = 5,  Nsamples train = 1076.0, Personal SCO - BAcc = 0.74\n",
      "Patient 8, Nclass train = 5, Nclass test = 3,  Nsamples train = 2182.0, Personal SCO - BAcc = 0.69\n",
      "Patient 11, Nclass train = 5, Nclass test = 5,  Nsamples train = 1636.0, Personal SCO - BAcc = 0.43\n",
      "Patient 14, Nclass train = 5, Nclass test = 5,  Nsamples train = 1606.0, Personal SCO - BAcc = 0.48\n",
      "Patient 15, Nclass train = 5, Nclass test = 5,  Nsamples train = 1863.0, Personal SCO - BAcc = 0.44\n",
      "Patient 16, Nclass train = 5, Nclass test = 5,  Nsamples train = 2184.0, Personal SCO - BAcc = 0.46\n",
      "Patient 19, Nclass train = 5, Nclass test = 3,  Nsamples train = 1255.0, Personal SCO - BAcc = 0.73\n",
      "Patient 24, Nclass train = 5, Nclass test = 5,  Nsamples train = 1087.0, Personal SCO - BAcc = 0.75\n",
      "Median BAcc - Patient Specific (SCO) = 0.65157867467\n",
      "Avg train size = 1601.27272727\n"
     ]
    }
   ],
   "source": [
    "PSpec_acc = np.zeros(len(PatientCodes)) \n",
    "Nsamples = np.zeros(len(PatientCodes))\n",
    "acc_class_subj = [] #accuracy per class for each subject\n",
    "\n",
    "cmat_PSpec = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_PSpec = {} \n",
    "recall_PSpec ={}\n",
    "\n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = SCOData[(SCOData['SubjID'] == s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s)]\n",
    "    Nclasstrain = len(train['Label'].unique())\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    Nsamples[k] = ytrain.shape[0]\n",
    "\n",
    "    RF = RandomForestClassifier(n_estimators=50,random_state=0)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    PSpec_acc[k],acc_class = Balanced_acc(ypred,ytest)\n",
    "    \n",
    "    #confusion matrix\n",
    "    cmat = confusion_matrix(ytest, ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "    prec,recall = prec_rec(cmat)\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(np.array(s)) #subj code\n",
    "    cmat_PSpec.update({key:cmat})\n",
    "    prec_PSpec.update({s:prec})\n",
    "    recall_PSpec.update({s:recall})\n",
    "    \n",
    "    print 'Patient {}, Nclass train = {}, Nclass test = {},  Nsamples train = {}, Personal SCO - BAcc = {:.2f}'.format(s,Nclasstrain,Nclasses,Nsamples[k],PSpec_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Median BAcc - Patient Specific (SCO) = %s'%np.median(PSpec_acc)\n",
    "print 'Avg train size = {}'.format(np.mean(Nsamples))\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_PSpec_mean = np.nanmean(np.asarray(prec_PSpec.values()),axis=0)\n",
    "rec_PSpec_mean = np.nanmean(np.asarray(recall_PSpec.values()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the dict to matlab format \n",
    "scipy.io.savemat('cmatPSpec',cmat_PSpec)\n",
    "np.savetxt('precisionPSpec.csv', prec_PSpec_mean, delimiter=',') \n",
    "np.savetxt('recallPSpec.csv', rec_PSpec_mean, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal CBR (Patient and Device specific model) \n",
    "Leave One Session Out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nclass train = 5, Nclass test =5, BAcc = 0.76\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.83\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.86\n",
      "Patient 1, Device Specific model - BAcc = 0.82\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.76\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.51\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.73\n",
      "Patient 2, Device Specific model - BAcc = 0.67\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.74\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.54\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.59\n",
      "Patient 5, Device Specific model - BAcc = 0.63\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.63\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.75\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.89\n",
      "Patient 6, Device Specific model - BAcc = 0.76\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.94\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.74\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.96\n",
      "Patient 8, Device Specific model - BAcc = 0.88\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.44\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.53\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.51\n",
      "Patient 11, Device Specific model - BAcc = 0.49\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.68\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.75\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.89\n",
      "Patient 14, Device Specific model - BAcc = 0.77\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.59\n",
      "Nclass train = 5, Nclass test =3, BAcc = 0.97\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.60\n",
      "Patient 15, Device Specific model - BAcc = 0.72\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.63\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.65\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.80\n",
      "Patient 16, Device Specific model - BAcc = 0.70\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.54\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.98\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.81\n",
      "Patient 19, Device Specific model - BAcc = 0.78\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.85\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.85\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.62\n",
      "Patient 24, Device Specific model - BAcc = 0.78\n",
      "Median BAcc - Device Specific (CBR) = 0.759794088869\n",
      "Avg train size = 999.757575758\n"
     ]
    }
   ],
   "source": [
    "DSpec_acc = np.zeros(len(PatientCodes)) \n",
    "Nsamples = np.zeros(len(PatientCodes))\n",
    "Nsessions = 3\n",
    "\n",
    "cmat_DSpec = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_DSpec = {} \n",
    "recall_DSpec ={}\n",
    "k = 0\n",
    "\n",
    "for s in PatientCodes:\n",
    "    cmat = np.zeros((5,5)) #temporary arrays to store cmat, prec and recall in each session\n",
    "    prec = np.zeros(5)\n",
    "    recall = np.zeros(5)\n",
    "\n",
    "    data =  CBRData[(CBRData['SubjID'] == s)] \n",
    "    Bacc = np.zeros(Nsessions)\n",
    "    for session in range(1,Nsessions+1):\n",
    "                  \n",
    "        test = data[data['Session'] == session]\n",
    "        train = data[data['Session'] != session]\n",
    "        Nclasstrain = len(train['Label'].unique())\n",
    "        Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "        Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "        ytrain = train.select_columns(label_cols).to_numpy()\n",
    "        ytrain = ytrain.reshape(-1)\n",
    "        Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "        ytest = test.select_columns(label_cols).to_numpy()\n",
    "        ytest = ytest.reshape(-1)\n",
    "        Nsamples[k] = Nsamples[k]+ytrain.shape[0]\n",
    "\n",
    "        RF = RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "        RF = RF.fit(Xtrain,ytrain)\n",
    "        ypred = RF.predict(Xtest)\n",
    "        #acc = sum(ypred == ytest)/len(ytest)\n",
    "        #balanced accuracy on each session\n",
    "        Bacc[session-1],acc_class = Balanced_acc(ypred,ytest)\n",
    "        print 'Nclass train = {}, Nclass test ={}, BAcc = {:.2f}'.format(Nclasstrain,Nclasses,Bacc[session-1])\n",
    "        \n",
    "        #confusion matrix, prec and recall in each session\n",
    "        cmat_tmp = confusion_matrix(ytest,ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "        cmat += cmat_tmp\n",
    "        pr,re = prec_rec(cmat_tmp)\n",
    "        prec += pr\n",
    "        recall += re\n",
    "\n",
    "    DSpec_acc[k] = Bacc.mean() #the CV BAcc on 3 sessions \n",
    "    Nsamples[k] = Nsamples[k]/len(range(1,Nsessions+1)) #mean number of samples across sessions    \n",
    "    #mean confusion matrix (instances), precision and recall on 3 sessions\n",
    "    avgcmat = cmat/Nsessions\n",
    "    prec = prec/Nsessions\n",
    "    recall = recall/Nsessions\n",
    "\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(np.array(s)) #subj code\n",
    "    cmat_DSpec.update({key:avgcmat})     #the confusion matrix with instances from the 4 sessions\n",
    "    prec_DSpec.update({s:prec})\n",
    "    recall_DSpec.update({s:recall})\n",
    "   \n",
    "    print 'Patient {}, Device Specific model - BAcc = {:.2f}'.format(s,DSpec_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Median BAcc - Device Specific (CBR) = %s'%(np.median(DSpec_acc))\n",
    "print 'Avg train size = {}'.format(np.mean(Nsamples))\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_DSpec_mean = np.nanmean(np.asarray(prec_DSpec.values()),axis=0)\n",
    "rec_DSpec_mean = np.nanmean(np.asarray(recall_DSpec.values()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save the dict to matlab format \n",
    "scipy.io.savemat('cmatDSpec',cmat_DSpec)\n",
    "np.savetxt('precisionDSpec.csv', prec_DSpec_mean, delimiter=',') \n",
    "np.savetxt('recallDSpec.csv', rec_DSpec_mean, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble results for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.464898    0.51884631  0.6460751   0.72130591  0.81941724]\n",
      " [ 0.39534911  0.49705282  0.46467181  0.54641183  0.66640783]\n",
      " [ 0.45820613  0.50928317  0.54516304  0.65157867  0.62684499]\n",
      " [ 0.57510649  0.56908657  0.60966302  0.7438839   0.75979409]\n",
      " [ 0.35719858  0.46364216  0.63736381  0.6913094   0.87778724]\n",
      " [ 0.53808672  0.52784409  0.57850914  0.42806913  0.4936162 ]\n",
      " [ 0.53400056  0.60009651  0.6025275   0.47528689  0.77433946]\n",
      " [ 0.53581328  0.5713727   0.67393761  0.44079779  0.72243056]\n",
      " [ 0.52738244  0.55567334  0.59662325  0.45840207  0.69537655]\n",
      " [ 0.55105444  0.83379062  0.89697221  0.72716989  0.77757322]\n",
      " [ 0.60378523  0.59033602  0.67279505  0.75460028  0.7764429 ]]\n"
     ]
    }
   ],
   "source": [
    "acc_all=np.vstack((SOacc,ISpec_acc,ISpecCBR_acc,PSpec_acc,DSpec_acc)).T\n",
    "print acc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njBHiAJAxQhwAMkaIA0DGCHEAyNj/A9cp3T/xBnwYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130068a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.boxplot(acc_all)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53400055983576222"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(SOacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55567333631468108"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(ISpec_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60966301654077415"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(ISpecCBR_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65157867467006247"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(PSpec_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75979408886883126"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(DSpec_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('results.csv', acc_all, delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.46684448,  0.7242379 ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(PSpec_acc,[25,75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on Patient 1, Train samples=8375, Test samples=1288, Nclass test=5\n",
      "BAcc = 0.52\n",
      "Test on Patient 2, Train samples=8375, Test samples=991, Nclass test=5\n",
      "BAcc = 0.39\n",
      "Test on Patient 5, Train samples=8375, Test samples=1358, Nclass test=5\n",
      "BAcc = 0.45\n",
      "Test on Patient 6, Train samples=8375, Test samples=2246, Nclass test=5\n",
      "BAcc = 0.60\n",
      "Test on Patient 8, Train samples=8375, Test samples=856, Nclass test=3\n",
      "BAcc = 0.36\n",
      "Test on Patient 11, Train samples=8375, Test samples=1207, Nclass test=5\n",
      "BAcc = 0.52\n",
      "Test on Patient 14, Train samples=8375, Test samples=1778, Nclass test=5\n",
      "BAcc = 0.53\n",
      "Test on Patient 15, Train samples=8375, Test samples=3177, Nclass test=5\n",
      "BAcc = 0.48\n",
      "Test on Patient 16, Train samples=8375, Test samples=1126, Nclass test=5\n",
      "BAcc = 0.53\n",
      "Test on Patient 19, Train samples=8375, Test samples=1020, Nclass test=3\n",
      "BAcc = 0.64\n",
      "Test on Patient 24, Train samples=8375, Test samples=1449, Nclass test=5\n",
      "BAcc = 0.64\n",
      "\n",
      "median Bacc - Healthy model = 0.519083682588\n"
     ]
    }
   ],
   "source": [
    "col_names = HealthyData.column_names()\n",
    "label_cols = col_names[-1:] #the : is used to return a list with one element \n",
    "feature_cols = col_names[2:-1]\n",
    "\n",
    "Xtrain = HealthyData.select_columns(feature_cols).to_numpy()\n",
    "ytrain = HealthyData.select_columns(label_cols).to_numpy()\n",
    "ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100,random_state=0)\n",
    "clf = clf.fit(Xtrain,ytrain)\n",
    "\n",
    "#test on each patient (CBR)\n",
    "SOacc = np.zeros(len(PatientCodes))\n",
    "acc_class_subj = [] #accuracy per class for each subject\n",
    "cmat_H = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_H = {} \n",
    "recall_H ={}\n",
    "k = 0\n",
    "\n",
    "for s in PatientCodes:\n",
    "    test = CBRData[(CBRData['SubjID'] == s)]\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "    print 'Test on Patient %s, Train samples=%s, Test samples=%s, Nclass test=%s'%(s,len(ytrain),len(ytest),Nclasses)\n",
    "    ypred = clf.predict(Xtest)\n",
    "\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #SOacc[k] = acc\n",
    "\n",
    "    #balanced accuracy\n",
    "    SOacc[k],acc_class = Balanced_acc(ypred,ytest)\n",
    "    acc_class_subj.append(acc_class)  \n",
    "    \n",
    "    #confusion matrix\n",
    "    cmat = confusion_matrix(ytest, ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "    prec,recall = prec_rec(cmat)\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(np.array(s)) #subj code\n",
    "    cmat_H.update({key:cmat})\n",
    "    prec_H.update({s:prec})\n",
    "    recall_H.update({s:recall})\n",
    "    \n",
    "    print 'BAcc = {:.2f}'.format(SOacc[k])\n",
    "    k = k+1\n",
    "\n",
    "print '\\nmedian Bacc - Healthy model = %s'%np.median(SOacc)\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_H_mean = np.nanmean(np.asarray(prec_H.values()),axis=0)\n",
    "rec_H_mean = np.nanmean(np.asarray(recall_H.values()),axis=0)\n",
    "#acc_class_subj_mean = np.nanmean(acc_class_subj,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global model simulations\n",
    "Train on increasing number of healthy subjects (from 1 to 11) and test on 1 CBR patient. Run Nruns times by randomzing subjects in each run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Healthy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 2 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 3 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 4 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 5 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 6 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 7 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 8 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 9 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 10 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 11 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "Elapsed time=29523.37 secs\n"
     ]
    }
   ],
   "source": [
    "col_names = HealthyData.column_names()\n",
    "label_cols = col_names[-1:] #the : is used to return a list with one element \n",
    "feature_cols = col_names[2:-1]\n",
    "\n",
    "Nruns = 1000 #total # of runs\n",
    "Ntrain = len(HealthyData['SubjID'].unique()) #the total number of healthy to train on\n",
    "Bacc_all = np.zeros((Nruns,Ntrain)) #contains the Bacc for each run \n",
    "\n",
    "t0 = time.time()\n",
    "#loop through num subj to train on\n",
    "for n in range(Ntrain):\n",
    "    print 'train on {} subjects'.format(n+1)\n",
    "    for run in range(1,Nruns+1):\n",
    "        if run%100 == 0:\n",
    "            print 'run={}/{}'.format(run,Nruns)       \n",
    "        #pick n subj to train \n",
    "        np.random.shuffle(HealthyCodes)\n",
    "        subjtrain = HealthyCodes[0:n+1]\n",
    "        train = HealthyData.filter_by(subjtrain,'SubjID')\n",
    "        test = np.random.shuffle(PatientCodes)\n",
    "        subjtest = PatientCodes[0] #pick one subj to test\n",
    "        test = CBRData.filter_by(subjtest,'SubjID')\n",
    "        #print 'Run=%s, Train on subj %s, test on patient %s'%(run,train['SubjID'].unique(),test['SubjID'].unique())\n",
    "\n",
    "        Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "        ytrain = train.select_columns(label_cols).to_numpy()\n",
    "        ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "        Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "        ytest = test.select_columns(label_cols).to_numpy()\n",
    "        ytest = ytest.reshape(-1)\n",
    "\n",
    "        RF = RandomForestClassifier(n_estimators=10)\n",
    "        RF = RF.fit(Xtrain,ytrain)\n",
    "        ypred = RF.predict(Xtest)\n",
    "\n",
    "        #acc = sum(ypred == ytest)/len(ytest)\n",
    "        #balanced accuracy for current run\n",
    "        Bacc_all[run-1,n],acc_class = Balanced_acc(ypred,ytest)\n",
    "        #print 'Bacc = {:.2f}'.format(Bacc_all[run,n])\n",
    "\n",
    "t1 = time.time()\n",
    "print 'Elapsed time=%.2f secs'%(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('results_GlobalH.csv', Bacc_all, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Global SCO Model simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 2 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 3 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 4 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 5 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 6 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 7 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 8 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 9 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 10 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "Elapsed time=96572.86 secs\n"
     ]
    }
   ],
   "source": [
    "col_names = SCOData.column_names()\n",
    "label_cols = col_names[-1:] #the : is used to return a list with one element \n",
    "feature_cols = col_names[2:-1]\n",
    "\n",
    "Nruns = 1000 #total # of runs\n",
    "Ntrain = len(SCOData['SubjID'].unique()) #the total number of patients (SCO)\n",
    "Bacc_all = np.zeros((Nruns,Ntrain-1)) #contains the Bacc for each run \n",
    "\n",
    "t0 = time.time()\n",
    "#loop through num subj to train on\n",
    "for n in range(Ntrain-1): #-1 as one patient is out for test\n",
    "    print 'train on {} subjects'.format(n+1)\n",
    "    for run in range(1,Nruns+1):\n",
    "        if run%100 == 0:\n",
    "            print 'run={}/{}'.format(run,Nruns)       \n",
    "        #pick n subj to train (use last for test)\n",
    "        np.random.shuffle(PatientCodes)\n",
    "        subjtrain = PatientCodes[0:n+1]\n",
    "        train = SCOData.filter_by(subjtrain,'SubjID')\n",
    "        subjtest = PatientCodes[n+1] #pick one patient to test (the last, not in train)\n",
    "        test = CBRData.filter_by(subjtest,'SubjID')\n",
    "        #print 'Run=%s, Train on subj %s, test on patient %s'%(run,train['SubjID'].unique(),test['SubjID'].unique())\n",
    "\n",
    "        Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "        ytrain = train.select_columns(label_cols).to_numpy()\n",
    "        ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "        Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "        ytest = test.select_columns(label_cols).to_numpy()\n",
    "        ytest = ytest.reshape(-1)\n",
    "\n",
    "        RF = RandomForestClassifier(n_estimators=10)\n",
    "        RF = RF.fit(Xtrain,ytrain)\n",
    "        ypred = RF.predict(Xtest)\n",
    "\n",
    "        #acc = sum(ypred == ytest)/len(ytest)\n",
    "        #balanced accuracy for current run\n",
    "        Bacc_all[run-1,n],acc_class = Balanced_acc(ypred,ytest)\n",
    "        #print 'Bacc = {:.2f}'.format(Bacc_all[run-1,n])\n",
    "t1 = time.time()\n",
    "print 'Elapsed time=%.2f secs'%(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('results_GlobalP.csv', Bacc_all, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Global CBR Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 2 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 3 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 4 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 5 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 6 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 7 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 8 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 9 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "train on 10 subjects\n",
      "run=100/1000\n",
      "run=200/1000\n",
      "run=300/1000\n",
      "run=400/1000\n",
      "run=500/1000\n",
      "run=600/1000\n",
      "run=700/1000\n",
      "run=800/1000\n",
      "run=900/1000\n",
      "run=1000/1000\n",
      "Elapsed time=38237.74 secs\n"
     ]
    }
   ],
   "source": [
    "col_names = CBRData.column_names()\n",
    "label_cols = col_names[-1:] #the : is used to return a list with one element \n",
    "feature_cols = col_names[2:-1]\n",
    "\n",
    "Nruns = 1000 #total # of runs\n",
    "Ntrain = len(CBRData['SubjID'].unique()) #the total number of patients (CBR)\n",
    "Bacc_all = np.zeros((Nruns,Ntrain-1)) #contains the Bacc for each run \n",
    "\n",
    "t0 = time.time()\n",
    "#loop through num subj to train on\n",
    "for n in range(Ntrain-1): #-1 as one patient is out for test\n",
    "    print 'train on {} subjects'.format(n+1)\n",
    "    for run in range(1,Nruns+1):\n",
    "        if run%100 == 0:\n",
    "            print 'run={}/{}'.format(run,Nruns)       \n",
    "        #pick n subj to train (use last for test)\n",
    "        np.random.shuffle(PatientCodes)\n",
    "        subjtrain = PatientCodes[0:n+1]\n",
    "        train = CBRData.filter_by(subjtrain,'SubjID')\n",
    "        subjtest = PatientCodes[n+1] #pick one patient to test (the last, not in train)\n",
    "        test = CBRData.filter_by(subjtest,'SubjID')\n",
    "        #print 'Run=%s, Train on subj %s, test on patient %s'%(run,train['SubjID'].unique(),test['SubjID'].unique())\n",
    "\n",
    "        Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "        ytrain = train.select_columns(label_cols).to_numpy()\n",
    "        ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "        Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "        ytest = test.select_columns(label_cols).to_numpy()\n",
    "        ytest = ytest.reshape(-1)\n",
    "\n",
    "        RF = RandomForestClassifier(n_estimators=50,n_jobs=-1)\n",
    "        RF = RF.fit(Xtrain,ytrain)\n",
    "        ypred = RF.predict(Xtest)\n",
    "\n",
    "        #acc = sum(ypred == ytest)/len(ytest)\n",
    "        #balanced accuracy for current run\n",
    "        Bacc_all[run-1,n],acc_class = Balanced_acc(ypred,ytest)\n",
    "        #print 'Bacc = {:.2f}'.format(Bacc_all[run-1,n])\n",
    "t1 = time.time()\n",
    "print 'Elapsed time=%.2f secs'%(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('results_GlobalP_CBR.csv', Bacc_all, delimiter=',') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

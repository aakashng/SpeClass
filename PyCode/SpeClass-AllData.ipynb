{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import graphlab\n",
    "import scipy #to save mat files\n",
    "import time  #to time code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#balanced accuracy\n",
    "def Balanced_acc(ypred,ytest):\n",
    "    acc_c = 0\n",
    "    acc_class = np.zeros(5) #the accuracy per class\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "        acc_class[c] = sum(correct)/len(correct)\n",
    "\n",
    "    Bacc = acc_c/len(np.unique(ytest))\n",
    "    return Bacc,acc_class\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(5)\n",
    "    plt.xticks(tick_marks, ['Sit','StairsDw','StairsUp','Stand','Walk'], rotation=45)\n",
    "    plt.yticks(tick_marks, ['Sit','StairsDw','StairsUp','Stand','Walk'])\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def prec_rec(cmat):\n",
    "    tpfp = cmat.sum(axis=1)\n",
    "    tpfn = cmat.sum(axis=0)\n",
    "    prec = cmat.diagonal()/tpfp\n",
    "    recall = cmat.diagonal()/tpfn\n",
    "    return prec,recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to llonini@ricres.org and will expire on November 11, 2016.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\llonini\\AppData\\Local\\Temp\\graphlab_server_1475385144.log.0\n"
     ]
    }
   ],
   "source": [
    "HealthyData = graphlab.SFrame.read_csv('../../Datasets/Cbrace/HealthyData.csv',verbose=False)\n",
    "CBRData = graphlab.SFrame.read_csv('../../Datasets/Cbrace/PatientCBRData.csv',verbose=False)\n",
    "SCOData = graphlab.SFrame.read_csv('../../Datasets/Cbrace/PatientSCOData.csv',verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51 52 53 54 55 56 57 58 59 60 61]\n",
      "[1L, 2L, 5L, 6L, 8L, 11L, 12L, 13L, 14L, 15L, 16L, 19L]\n"
     ]
    }
   ],
   "source": [
    "HealthyCodes = HealthyData['SubjID'].unique()\n",
    "HealthyCodes = HealthyCodes.sort()\n",
    "HealthyCodes = HealthyCodes.to_numpy()\n",
    "print HealthyCodes\n",
    "PatientCodes = CBRData['SubjID'].unique()\n",
    "PatientCodes = PatientCodes.sort()\n",
    "print PatientCodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PatientCodes = np.array([1, 2, 5, 6, 8, 11, 14, 15, 16, 19]) #all patients with 4 sessions in SCO and CBR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use 4 sessions from both CBR and SCO data. Remove stairs CBR data for patients who don't have at least 2 sessions with stairs data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect SCO Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 [0 1 2 3 4]\n",
      "1 2 [0 1 2 3 4]\n",
      "1 3 [0 1 2 3 4]\n",
      "1 4 [0 1 2 3 4]\n",
      "2 1 [0 1 2 3 4]\n",
      "2 2 [0 1 2 3 4]\n",
      "2 3 [0 3 4]\n",
      "2 4 [0 1 2 3 4]\n",
      "5 1 [0 3 4]\n",
      "5 2 [0 1 2 3 4]\n",
      "5 3 [0 1 2 3 4]\n",
      "6 1 [0 1 2 3 4]\n",
      "6 2 [0 1 2 3 4]\n",
      "6 3 [0 1 2 3 4]\n",
      "6 4 [0 1 2 3 4]\n",
      "8 1 [0 1 2 3 4]\n",
      "8 2 [0 3 4]\n",
      "8 3 [0 3 4]\n",
      "8 4 [0 3 4]\n",
      "11 1 [0 3 4]\n",
      "11 2 [0 3 4]\n",
      "11 3 [0 3 4]\n",
      "11 4 [0 1 2 3 4]\n",
      "14 1 [0 1 2 3 4]\n",
      "14 2 [0 1 2 3 4]\n",
      "14 3 [0 1 2 3 4]\n",
      "14 4 [0 1 2 3 4]\n",
      "15 1 [0 3 4]\n",
      "15 2 [0 3 4]\n",
      "15 3 [0 1 2 3 4]\n",
      "16 1 [0 1 2 3 4]\n",
      "16 2 [0 3 4]\n",
      "16 3 [0 1 2 3 4]\n",
      "16 4 [0 1 2 3 4]\n",
      "19 1 [0 3 4]\n",
      "19 2 [0 1 2 3 4]\n",
      "19 3 [0 3 4]\n"
     ]
    }
   ],
   "source": [
    "for s in PatientCodes:\n",
    "    data = SCOData[SCOData['SubjID']==s]\n",
    "    for sess in np.unique(data['Session']):\n",
    "        print s,sess,np.unique(data[data['Session']==sess]['Label'].unique().sort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18762\n"
     ]
    }
   ],
   "source": [
    "print SCOData.num_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect CBR Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 [0 1 2 3 4]\n",
      "1 2 [0 1 2 3 4]\n",
      "1 3 [0 1 2 3 4]\n",
      "1 4 [0 1 2 3 4]\n",
      "2 1 [0 1 2 3 4]\n",
      "2 2 [0 1 2 3 4]\n",
      "2 3 [0 1 2 3 4]\n",
      "2 4 [0 1 2 3 4]\n",
      "5 1 [0 1 2 3 4]\n",
      "5 2 [0 1 2 3 4]\n",
      "5 3 [0 1 2 3 4]\n",
      "5 4 [0 1 2 3 4]\n",
      "6 1 [0 1 3 4]\n",
      "6 2 [0 1 2 3 4]\n",
      "6 3 [0 1 2 3 4]\n",
      "6 4 [0 1 2 3 4]\n",
      "8 1 [0 3 4]\n",
      "8 2 [0 3 4]\n",
      "8 3 [0 3 4]\n",
      "8 4 [0 1 2 3 4]\n",
      "11 1 [0 3 4]\n",
      "11 2 [0 1 2 3 4]\n",
      "11 3 [0 1 2 3 4]\n",
      "11 4 [0 1 2 3 4]\n",
      "14 1 [0 3 4]\n",
      "14 2 [0 3 4]\n",
      "14 3 [0 1 2 3 4]\n",
      "14 4 [0 1 2 3 4]\n",
      "15 1 [0 3 4]\n",
      "15 2 [0 1 2 3 4]\n",
      "15 3 [0 3 4]\n",
      "15 4 [0 1 2 3 4]\n",
      "16 1 [0 1 2 3 4]\n",
      "16 2 [0 1 2 3 4]\n",
      "16 3 [0 1 2 3 4]\n",
      "16 4 [0 1 2 3 4]\n",
      "19 1 [0 3 4]\n",
      "19 2 [0 3 4]\n",
      "19 3 [0 3 4]\n",
      "19 4 [0 3 4]\n"
     ]
    }
   ],
   "source": [
    "for s in PatientCodes:\n",
    "    data = CBRData[CBRData['SubjID']==s]\n",
    "    for sess in np.unique(data['Session']):\n",
    "        print s,sess,np.unique(data[data['Session']==sess]['Label'].unique().sort())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remove stairs from CBR08 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [0L, 1L, 2L, 3L, 4L]\n",
      "2 [0L, 1L, 2L, 3L, 4L]\n",
      "5 [0L, 1L, 2L, 3L, 4L]\n",
      "6 [0L, 1L, 2L, 3L, 4L]\n",
      "8 [0L, 3L, 4L]\n",
      "11 [0L, 1L, 2L, 3L, 4L]\n",
      "14 [0L, 1L, 2L, 3L, 4L]\n",
      "15 [0L, 1L, 2L, 3L, 4L]\n",
      "16 [0L, 1L, 2L, 3L, 4L]\n",
      "19 [0L, 3L, 4L]\n"
     ]
    }
   ],
   "source": [
    "Nostairs = [8] #the patient to remove stairs \n",
    "CBRDatanew = CBRData.filter_by(Nostairs,'SubjID',exclude=True)\n",
    "for s in Nostairs:\n",
    "    data = CBRData[(CBRData['SubjID']==s)].filter_by([0,3,4],'Label')\n",
    "    CBRDatanew=CBRDatanew.append(data)\n",
    "\n",
    "for s in PatientCodes:\n",
    "    print s,CBRDatanew[CBRDatanew['SubjID']==s]['Label'].unique().sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the CBR subjects have stairs except 2 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22354\n",
      "22323\n"
     ]
    }
   ],
   "source": [
    "print CBRData.num_rows()\n",
    "print CBRDatanew.num_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CBRData = CBRDatanew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Healthy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on Patient 1, Train samples=8375, Test samples=1678, Nclass test=5\n",
      "BAcc = 0.47\n",
      "Test on Patient 2, Train samples=8375, Test samples=1458, Nclass test=5\n",
      "BAcc = 0.34\n",
      "Test on Patient 5, Train samples=8375, Test samples=1773, Nclass test=5\n",
      "BAcc = 0.45\n",
      "Test on Patient 6, Train samples=8375, Test samples=2916, Nclass test=5\n",
      "BAcc = 0.58\n",
      "Test on Patient 8, Train samples=8375, Test samples=1179, Nclass test=3\n",
      "BAcc = 0.34\n",
      "Test on Patient 11, Train samples=8375, Test samples=1708, Nclass test=5\n",
      "BAcc = 0.53\n",
      "Test on Patient 14, Train samples=8375, Test samples=1976, Nclass test=5\n",
      "BAcc = 0.50\n",
      "Test on Patient 15, Train samples=8375, Test samples=3511, Nclass test=5\n",
      "BAcc = 0.45\n",
      "Test on Patient 16, Train samples=8375, Test samples=1734, Nclass test=5\n",
      "BAcc = 0.57\n",
      "Test on Patient 19, Train samples=8375, Test samples=1565, Nclass test=3\n",
      "BAcc = 0.57\n",
      "\n",
      "median Bacc - Healthy model = 0.484652798249\n"
     ]
    }
   ],
   "source": [
    "col_names = HealthyData.column_names()\n",
    "label_cols = col_names[-1:] #the : is used to return a list with one element \n",
    "feature_cols = col_names[2:-1]\n",
    "\n",
    "Xtrain = HealthyData.select_columns(feature_cols).to_numpy()\n",
    "ytrain = HealthyData.select_columns(label_cols).to_numpy()\n",
    "ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=100)\n",
    "RF = RF.fit(Xtrain,ytrain)\n",
    "\n",
    "#test on each patient (CBR)\n",
    "SOacc = np.zeros(len(PatientCodes))\n",
    "acc_class_subj = [] #accuracy per class for each subject\n",
    "cmat_H = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_H = {} \n",
    "recall_H ={}\n",
    "k = 0\n",
    "\n",
    "for s in PatientCodes:\n",
    "    test = CBRData[(CBRData['SubjID'] == s)]\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "    print 'Test on Patient %s, Train samples=%s, Test samples=%s, Nclass test=%s'%(s,len(ytrain),len(ytest),Nclasses)\n",
    "    ypred = RF.predict(Xtest)\n",
    "\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #SOacc[k] = acc\n",
    "\n",
    "    #balanced accuracy\n",
    "    SOacc[k],acc_class = Balanced_acc(ypred,ytest)\n",
    "    acc_class_subj.append(acc_class)  \n",
    "    \n",
    "    #confusion matrix\n",
    "    cmat = confusion_matrix(ytest, ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "    prec,recall = prec_rec(cmat)\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(s) #subj code\n",
    "    cmat_H.update({key:cmat})\n",
    "    prec_H.update({s:prec})\n",
    "    recall_H.update({s:recall})\n",
    "    \n",
    "    print 'BAcc = {:.2f}'.format(SOacc[k])\n",
    "    k = k+1\n",
    "\n",
    "print '\\nmedian Bacc - Healthy model = %s'%np.median(SOacc)\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_H_mean = np.nanmean(np.asarray(prec_H.values()),axis=0)\n",
    "rec_H_mean = np.nanmean(np.asarray(recall_H.values()),axis=0)\n",
    "#acc_class_subj_mean = np.nanmean(acc_class_subj,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save data\n",
    "#save the dict to matlab format \n",
    "scipy.io.savemat('cmatHealthy',cmat_H)\n",
    "np.savetxt('precisionHealthy.csv', prec_H_mean, delimiter=',') \n",
    "np.savetxt('recallHealthy.csv', rec_H_mean, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global model SCO (Leave one subject out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Nclass train = 5, Nclass test = 5, Nsamples train = 17471.0, Global SCO - BAcc = 0.53\n",
      "Patient 2, Nclass train = 5, Nclass test = 5, Nsamples train = 17055.0, Global SCO - BAcc = 0.43\n",
      "Patient 5, Nclass train = 5, Nclass test = 5, Nsamples train = 16386.0, Global SCO - BAcc = 0.48\n",
      "Patient 6, Nclass train = 5, Nclass test = 5, Nsamples train = 17383.0, Global SCO - BAcc = 0.56\n",
      "Patient 8, Nclass train = 5, Nclass test = 3, Nsamples train = 16142.0, Global SCO - BAcc = 0.47\n",
      "Patient 11, Nclass train = 5, Nclass test = 5, Nsamples train = 17131.0, Global SCO - BAcc = 0.56\n",
      "Patient 14, Nclass train = 5, Nclass test = 5, Nsamples train = 16787.0, Global SCO - BAcc = 0.58\n",
      "Patient 15, Nclass train = 5, Nclass test = 5, Nsamples train = 16899.0, Global SCO - BAcc = 0.54\n",
      "Patient 16, Nclass train = 5, Nclass test = 5, Nsamples train = 16097.0, Global SCO - BAcc = 0.55\n",
      "Patient 19, Nclass train = 5, Nclass test = 3, Nsamples train = 17507.0, Global SCO - BAcc = 0.84\n",
      "Median BAcc - Impairment Specific (SCO) = 0.54677034247\n",
      "Avg train size = 16885.8\n"
     ]
    }
   ],
   "source": [
    "ISpec_acc = np.zeros(len(PatientCodes)) \n",
    "Nsamples = np.zeros(len(PatientCodes))\n",
    "acc_class_subj = [] #accuracy per class for each subject\n",
    "\n",
    "cmat_ISpec = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_ISpec = {} \n",
    "recall_ISpec ={}\n",
    "\n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = SCOData[(SCOData['SubjID'] != s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s)] \n",
    "    Nclasstrain = len(train['Label'].unique())\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    Nsamples[k] = ytrain.shape[0]\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=100)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    ISpec_acc[k],acc_class = Balanced_acc(ypred,ytest)\n",
    "    acc_class_subj.append(acc_class)\n",
    "    \n",
    "    #confusion matrix\n",
    "    cmat = confusion_matrix(ytest, ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "    prec,recall = prec_rec(cmat)\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(s) #subj code\n",
    "    cmat_ISpec.update({key:cmat})\n",
    "    prec_ISpec.update({s:prec})\n",
    "    recall_ISpec.update({s:recall})\n",
    "\n",
    "    print 'Patient {}, Nclass train = {}, Nclass test = {}, Nsamples train = {}, Global SCO - BAcc = {:.2f}'.format(s,Nclasstrain,Nclasses,Nsamples[k],ISpec_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Median BAcc - Impairment Specific (SCO) = %s'%np.median(ISpec_acc)\n",
    "print 'Avg train size = {}'.format(np.mean(Nsamples))\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_ISpec_mean = np.nanmean(np.asarray(prec_ISpec.values()),axis=0)\n",
    "rec_ISpec_mean = np.nanmean(np.asarray(recall_ISpec.values()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save the dict to matlab format \n",
    "scipy.io.savemat('cmatISpec',cmat_ISpec)\n",
    "np.savetxt('precisionISpec.csv', prec_ISpec_mean, delimiter=',') \n",
    "np.savetxt('recallISpec.csv', rec_ISpec_mean, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global model CBR (Leave one subject out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Nclass train = 5, Nclass test = 5, Global CBR model - BAcc = 0.61\n",
      "Patient 2, Nclass train = 5, Nclass test = 5, Global CBR model - BAcc = 0.44\n",
      "Patient 5, Nclass train = 5, Nclass test = 5, Global CBR model - BAcc = 0.54\n",
      "Patient 6, Nclass train = 5, Nclass test = 5, Global CBR model - BAcc = 0.57\n",
      "Patient 8, Nclass train = 5, Nclass test = 3, Global CBR model - BAcc = 0.56\n",
      "Patient 11, Nclass train = 5, Nclass test = 5, Global CBR model - BAcc = 0.57\n",
      "Patient 14, Nclass train = 5, Nclass test = 5, Global CBR model - BAcc = 0.54\n",
      "Patient 15, Nclass train = 5, Nclass test = 5, Global CBR model - BAcc = 0.60\n",
      "Patient 16, Nclass train = 5, Nclass test = 5, Global CBR model - BAcc = 0.60\n",
      "Patient 19, Nclass train = 5, Nclass test = 3, Global CBR model - BAcc = 0.88\n",
      "Median BAcc - Global CBR model = 0.57144592259\n"
     ]
    }
   ],
   "source": [
    "ISpecCBR_acc = np.zeros(len(PatientCodes)) \n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = CBRData[(CBRData['SubjID'] != s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s)] #test on 3 CBR sessions\n",
    "    Nclasstrain = len(train['Label'].unique())\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    ISpecCBR_acc[k],acc_class = Balanced_acc(ypred,ytest)\n",
    "    acc_class_subj.append(acc_class)   \n",
    "    print 'Patient {}, Nclass train = {}, Nclass test = {}, Global CBR model - BAcc = {:.2f}'.format(s,Nclasstrain,Nclasses,ISpecCBR_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Median BAcc - Global CBR model = %s'%np.median(ISpecCBR_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal SCO (Patient Specific model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Nclass train = 5, Nclass test = 5,  Nsamples train = 1291.0, Personal SCO - BAcc = 0.71\n",
      "Patient 2, Nclass train = 5, Nclass test = 5,  Nsamples train = 1707.0, Personal SCO - BAcc = 0.47\n",
      "Patient 5, Nclass train = 5, Nclass test = 5,  Nsamples train = 2376.0, Personal SCO - BAcc = 0.64\n",
      "Patient 6, Nclass train = 5, Nclass test = 5,  Nsamples train = 1379.0, Personal SCO - BAcc = 0.58\n",
      "Patient 8, Nclass train = 5, Nclass test = 3,  Nsamples train = 2620.0, Personal SCO - BAcc = 0.78\n",
      "Patient 11, Nclass train = 5, Nclass test = 5,  Nsamples train = 1631.0, Personal SCO - BAcc = 0.46\n",
      "Patient 14, Nclass train = 5, Nclass test = 5,  Nsamples train = 1975.0, Personal SCO - BAcc = 0.53\n",
      "Patient 15, Nclass train = 5, Nclass test = 5,  Nsamples train = 1863.0, Personal SCO - BAcc = 0.43\n",
      "Patient 16, Nclass train = 5, Nclass test = 5,  Nsamples train = 2665.0, Personal SCO - BAcc = 0.48\n",
      "Patient 19, Nclass train = 5, Nclass test = 3,  Nsamples train = 1255.0, Personal SCO - BAcc = 0.76\n",
      "Median BAcc - Patient Specific (SCO) = 0.5533702216\n",
      "Avg train size = 1876.2\n"
     ]
    }
   ],
   "source": [
    "PSpec_acc = np.zeros(len(PatientCodes)) \n",
    "Nsamples = np.zeros(len(PatientCodes))\n",
    "acc_class_subj = [] #accuracy per class for each subject\n",
    "\n",
    "cmat_PSpec = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_PSpec = {} \n",
    "recall_PSpec ={}\n",
    "\n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = SCOData[(SCOData['SubjID'] == s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s)]\n",
    "    Nclasstrain = len(train['Label'].unique())\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    Nsamples[k] = ytrain.shape[0]\n",
    "\n",
    "    RF = RandomForestClassifier(n_estimators=50)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    PSpec_acc[k],acc_class = Balanced_acc(ypred,ytest)\n",
    "    \n",
    "    #confusion matrix\n",
    "    cmat = confusion_matrix(ytest, ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "    prec,recall = prec_rec(cmat)\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(s) #subj code\n",
    "    cmat_PSpec.update({key:cmat})\n",
    "    prec_PSpec.update({s:prec})\n",
    "    recall_PSpec.update({s:recall})\n",
    "    \n",
    "    print 'Patient {}, Nclass train = {}, Nclass test = {},  Nsamples train = {}, Personal SCO - BAcc = {:.2f}'.format(s,Nclasstrain,Nclasses,Nsamples[k],PSpec_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Median BAcc - Patient Specific (SCO) = %s'%np.median(PSpec_acc)\n",
    "print 'Avg train size = {}'.format(np.mean(Nsamples))\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_PSpec_mean = np.nanmean(np.asarray(prec_PSpec.values()),axis=0)\n",
    "rec_PSpec_mean = np.nanmean(np.asarray(recall_PSpec.values()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the dict to matlab format \n",
    "scipy.io.savemat('cmatPSpec',cmat_PSpec)\n",
    "np.savetxt('precisionPSpec.csv', prec_PSpec_mean, delimiter=',') \n",
    "np.savetxt('recallPSpec.csv', rec_PSpec_mean, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal CBR (Patient and Device specific model) \n",
    "Leave One Session Out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nclass train = 5, Nclass test =5, BAcc = 0.87\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.87\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.87\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.76\n",
      "Patient 1, Device Specific model - BAcc = 0.84\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.70\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.52\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.69\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.56\n",
      "Patient 2, Device Specific model - BAcc = 0.62\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.71\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.63\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.61\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.74\n",
      "Patient 5, Device Specific model - BAcc = 0.67\n",
      "Nclass train = 5, Nclass test =4, BAcc = 0.65\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.51\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.65\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.79\n",
      "Patient 6, Device Specific model - BAcc = 0.65\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.95\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.77\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.98\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.97\n",
      "Patient 8, Device Specific model - BAcc = 0.92\n",
      "Nclass train = 5, Nclass test =3, BAcc = 0.97\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.51\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.66\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.52\n",
      "Patient 11, Device Specific model - BAcc = 0.66\n",
      "Nclass train = 5, Nclass test =3, BAcc = 0.98\n",
      "Nclass train = 5, Nclass test =3, BAcc = 1.00\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.58\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.73\n",
      "Patient 14, Device Specific model - BAcc = 0.82\n",
      "Nclass train = 5, Nclass test =3, BAcc = 0.94\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.55\n",
      "Nclass train = 5, Nclass test =3, BAcc = 0.99\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.60\n",
      "Patient 15, Device Specific model - BAcc = 0.77\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.59\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.61\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.84\n",
      "Nclass train = 5, Nclass test =5, BAcc = 0.93\n",
      "Patient 16, Device Specific model - BAcc = 0.74\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.57\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.98\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.86\n",
      "Nclass train = 3, Nclass test =3, BAcc = 0.73\n",
      "Patient 19, Device Specific model - BAcc = 0.79\n",
      "Median BAcc - Device Specific (CBR) = 0.758419523895\n",
      "Avg train size = 1462.35\n"
     ]
    }
   ],
   "source": [
    "DSpec_acc = np.zeros(len(PatientCodes)) \n",
    "Nsamples = np.zeros(len(PatientCodes))\n",
    "\n",
    "cmat_DSpec = {} #store confusion mats, precision and recall for all subjects  \n",
    "prec_DSpec = {} \n",
    "recall_DSpec ={}\n",
    "k = 0\n",
    "\n",
    "for s in PatientCodes:\n",
    "    cmat = np.zeros((5,5)) #temporary arrays to store cmat, prec and recall in each session\n",
    "    prec = np.zeros(5)\n",
    "    recall = np.zeros(5)\n",
    "\n",
    "    data =  CBRData[(CBRData['SubjID'] == s)] \n",
    "    Bacc = np.zeros(4)\n",
    "    for session in range(1,5):\n",
    "                  \n",
    "        test = data[data['Session'] == session]\n",
    "        train = data[data['Session'] != session]\n",
    "        Nclasstrain = len(train['Label'].unique())\n",
    "        Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test data\n",
    "\n",
    "        Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "        ytrain = train.select_columns(label_cols).to_numpy()\n",
    "        ytrain = ytrain.reshape(-1)\n",
    "        Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "        ytest = test.select_columns(label_cols).to_numpy()\n",
    "        ytest = ytest.reshape(-1)\n",
    "        Nsamples[k] = Nsamples[k]+ytrain.shape[0]\n",
    "\n",
    "        RF = RandomForestClassifier(n_estimators=50)\n",
    "        RF = RF.fit(Xtrain,ytrain)\n",
    "        ypred = RF.predict(Xtest)\n",
    "        #acc = sum(ypred == ytest)/len(ytest)\n",
    "        #balanced accuracy on each session\n",
    "        Bacc[session-1],acc_class = Balanced_acc(ypred,ytest)\n",
    "        print 'Nclass train = {}, Nclass test ={}, BAcc = {:.2f}'.format(Nclasstrain,Nclasses,Bacc[session-1])\n",
    "        \n",
    "        #confusion matrix, prec and recall in each session\n",
    "        cmat_tmp = confusion_matrix(ytest,ypred,labels=[0,1,2,3,4]) #labels=[\"Sit\",\"Stairs Dw\",\"Stairs Up\",\"Stand\",\"Walk\"])\n",
    "        cmat += cmat_tmp\n",
    "        pr,re = prec_rec(cmat_tmp)\n",
    "        prec += pr\n",
    "        recall += re\n",
    "\n",
    "    DSpec_acc[k] = Bacc.mean() #the CV BAcc on 4 sessions \n",
    "    Nsamples[k] = Nsamples[k]/len(range(1,5)) #mean number of samples across sessions    \n",
    "    #mean confusion matrix (instances), precision and recall on 4 sessions\n",
    "    avgcmat = cmat/4\n",
    "    prec = prec/4\n",
    "    recall = recall/4\n",
    "\n",
    "    #assemble data in dicts\n",
    "    key = 'S'+np.array_str(s) #subj code\n",
    "    cmat_DSpec.update({key:avgcmat})     #the confusion matrix with instances from the 4 sessions\n",
    "    prec_DSpec.update({s:prec})\n",
    "    recall_DSpec.update({s:recall})\n",
    "   \n",
    "    print 'Patient {}, Device Specific model - BAcc = {:.2f}'.format(s,DSpec_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Median BAcc - Device Specific (CBR) = %s'%(np.median(DSpec_acc))\n",
    "print 'Avg train size = {}'.format(np.mean(Nsamples))\n",
    "\n",
    "#mean precision and recall per class\n",
    "prec_DSpec_mean = np.nanmean(np.asarray(prec_DSpec.values()),axis=0)\n",
    "rec_DSpec_mean = np.nanmean(np.asarray(recall_DSpec.values()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save the dict to matlab format \n",
    "scipy.io.savemat('cmatDSpec',cmat_DSpec)\n",
    "np.savetxt('precisionDSpec.csv', prec_DSpec_mean, delimiter=',') \n",
    "np.savetxt('recallDSpec.csv', rec_DSpec_mean, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble results for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.47312239  0.53312562  0.70683244  0.84290651]\n",
      " [ 0.33558537  0.42982671  0.46628651  0.61729721]\n",
      " [ 0.44556129  0.47831113  0.64382389  0.67289044]\n",
      " [ 0.58170215  0.56460008  0.57745354  0.6485444 ]\n",
      " [ 0.34331821  0.46815632  0.78147984  0.92022326]\n",
      " [ 0.53336708  0.56124551  0.45993864  0.66453179]\n",
      " [ 0.49618321  0.58457134  0.5292869   0.8217154 ]\n",
      " [ 0.44800536  0.54275763  0.42554211  0.77202348]\n",
      " [ 0.56998263  0.55078306  0.47694581  0.74481557]\n",
      " [ 0.56946109  0.84261744  0.75850682  0.78590696]]\n"
     ]
    }
   ],
   "source": [
    "acc_all=np.vstack((SOacc,ISpec_acc,PSpec_acc,DSpec_acc)).T\n",
    "print acc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x168cbdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(acc_all)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48465279824915253"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(SOacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54677034247049383"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(ISpec_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55337022160010463"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(PSpec_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75841952389499379"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(DSpec_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('results.csv', acc_all, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global model simulations\n",
    "Train on increasing number of healthy subjects (from 1 to 11) and test on 1 CBR patient. Run Nruns times by randomzing subjects in each run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Healthy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 2 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 3 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 4 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 5 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 6 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 7 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 8 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 9 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 10 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 11 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "Elapsed time=3975.95 secs\n"
     ]
    }
   ],
   "source": [
    "col_names = HealthyData.column_names()\n",
    "label_cols = col_names[-1:] #the : is used to return a list with one element \n",
    "feature_cols = col_names[2:-1]\n",
    "\n",
    "Nruns = 100 #total # of runs\n",
    "Ntrain = len(HealthyData['SubjID'].unique()) #the total number of healthy to train on\n",
    "Bacc_all = np.zeros((Nruns,Ntrain)) #contains the Bacc for each run \n",
    "\n",
    "t0 = time.time()\n",
    "#loop through num subj to train on\n",
    "for n in range(Ntrain):\n",
    "    print 'train on {} subjects'.format(n+1)\n",
    "    for run in range(1,Nruns+1):\n",
    "        if run%10 == 0:\n",
    "            print 'run={}/{}'.format(run,Nruns)       \n",
    "        #pick n subj to train \n",
    "        np.random.shuffle(HealthyCodes)\n",
    "        subjtrain = HealthyCodes[0:n+1]\n",
    "        train = HealthyData.filter_by(subjtrain,'SubjID')\n",
    "        test = np.random.shuffle(PatientCodes)\n",
    "        subjtest = PatientCodes[0] #pick one subj to test\n",
    "        test = CBRData.filter_by(subjtest,'SubjID')\n",
    "        #print 'Run=%s, Train on subj %s, test on patient %s'%(run,train['SubjID'].unique(),test['SubjID'].unique())\n",
    "\n",
    "        Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "        ytrain = train.select_columns(label_cols).to_numpy()\n",
    "        ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "        Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "        ytest = test.select_columns(label_cols).to_numpy()\n",
    "        ytest = ytest.reshape(-1)\n",
    "\n",
    "        RF = RandomForestClassifier(n_estimators=100)\n",
    "        RF = RF.fit(Xtrain,ytrain)\n",
    "        ypred = RF.predict(Xtest)\n",
    "\n",
    "        #acc = sum(ypred == ytest)/len(ytest)\n",
    "        #balanced accuracy for current run\n",
    "        Bacc_all[run-1,n],acc_class = Balanced_acc(ypred,ytest)\n",
    "        #print 'Bacc = {:.2f}'.format(Bacc_all[run,n])\n",
    "\n",
    "t1 = time.time()\n",
    "print 'Elapsed time=%.2f secs'%(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('results_GlobalH.csv', Bacc_all, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Patients Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 2 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 3 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 4 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 5 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 6 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 7 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 8 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "train on 9 subjects\n",
      "run=10/100\n",
      "run=20/100\n",
      "run=30/100\n",
      "run=40/100\n",
      "run=50/100\n",
      "run=60/100\n",
      "run=70/100\n",
      "run=80/100\n",
      "run=90/100\n",
      "run=100/100\n",
      "Elapsed time=8274.13 secs\n"
     ]
    }
   ],
   "source": [
    "col_names = SCOData.column_names()\n",
    "label_cols = col_names[-1:] #the : is used to return a list with one element \n",
    "feature_cols = col_names[2:-1]\n",
    "\n",
    "Nruns = 100 #total # of runs\n",
    "Ntrain = len(SCOData['SubjID'].unique()) #the total number of patients (SCO)\n",
    "Bacc_all = np.zeros((Nruns,Ntrain-1)) #contains the Bacc for each run \n",
    "\n",
    "t0 = time.time()\n",
    "#loop through num subj to train on\n",
    "for n in range(Ntrain-1): #-1 as one patient is out for test\n",
    "    print 'train on {} subjects'.format(n+1)\n",
    "    for run in range(1,Nruns+1):\n",
    "        if run%10 == 0:\n",
    "            print 'run={}/{}'.format(run,Nruns)       \n",
    "        #pick n subj to train (use last for test)\n",
    "        np.random.shuffle(PatientCodes)\n",
    "        subjtrain = PatientCodes[0:n+1]\n",
    "        train = SCOData.filter_by(subjtrain,'SubjID')\n",
    "        subjtest = PatientCodes[n+1] #pick one patient to test (the last, not in train)\n",
    "        test = CBRData.filter_by(subjtest,'SubjID')\n",
    "        #print 'Run=%s, Train on subj %s, test on patient %s'%(run,train['SubjID'].unique(),test['SubjID'].unique())\n",
    "\n",
    "        Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "        ytrain = train.select_columns(label_cols).to_numpy()\n",
    "        ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "        Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "        ytest = test.select_columns(label_cols).to_numpy()\n",
    "        ytest = ytest.reshape(-1)\n",
    "\n",
    "        RF = RandomForestClassifier(n_estimators=100)\n",
    "        RF = RF.fit(Xtrain,ytrain)\n",
    "        ypred = RF.predict(Xtest)\n",
    "\n",
    "        #acc = sum(ypred == ytest)/len(ytest)\n",
    "        #balanced accuracy for current run\n",
    "        Bacc_all[run-1,n],acc_class = Balanced_acc(ypred,ytest)\n",
    "        #print 'Bacc = {:.2f}'.format(Bacc_all[run-1,n])\n",
    "t1 = time.time()\n",
    "print 'Elapsed time=%.2f secs'%(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('results_GlobalP.csv', Bacc_all, delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
